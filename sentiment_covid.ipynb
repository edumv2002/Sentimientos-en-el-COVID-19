{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Sentimientos de Coranavirus Tweets NLP - Text Classification\n",
    "La base de datos utilizada en este proyecto ha sido extraída de Kaggle: https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification. Los ficheros de datos están en formato CSV y están almacenados en los ficheros `Corona_NLP_test.csv` y `Corona_NLP_train.csv`. Estos ficheros contienen tweets relacionados con el coronavirus, junto con su respectiva etiqueta de sentimiento (positivo, negativo o neutro).\n",
    "\n",
    "El objetivo de este proyecto es clasificar los tweets en las diferentes categorías. Para ello, se utilizará un modelo de clasificación de texto basado en técnicas de procesamiento de lenguaje natural (NLP).\n",
    "En primer lugar, importamos las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.models import Transformer_Classifier, Classifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n",
    "A continuación, cargamos la base de datos con pandas y visualizamos su información. La base de datos contiene 2 columnas: \"text\" (el tweet), \"sentiment\" (la etiqueta de sentimiento). La columna \"sentiment\" contiene las etiquetas que queremos predecir. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41157 entries, 0 to 41156\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   OriginalTweet  41157 non-null  object\n",
      " 1   Sentiment      41157 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 643.2+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   OriginalTweet  3798 non-null   object\n",
      " 1   Sentiment      3798 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 59.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('sentiment_data/Corona_NLP_train.csv', encoding='latin-1')\n",
    "df_test = pd.read_csv('sentiment_data/Corona_NLP_test.csv', encoding='latin-1')\n",
    "\n",
    "df_train = df_train[['OriginalTweet', 'Sentiment']]\n",
    "df_test = df_test[['OriginalTweet', 'Sentiment']]\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "print(df_train.info())\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos la distribución de las etiquetas de sentimiento en la base de datos. Para ello, utilizamos la función value_counts() de pandas para contar el número de tweets en cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contando valores de sentiment en train:\n",
      "Positive              11422\n",
      "Negative               9917\n",
      "Neutral                7713\n",
      "Extremely Positive     6624\n",
      "Extremely Negative     5481\n",
      "Name: Sentiment, dtype: int64\n",
      "Contando valores de sentiment en test:\n",
      "Negative              1041\n",
      "Positive               947\n",
      "Neutral                619\n",
      "Extremely Positive     599\n",
      "Extremely Negative     592\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Contando valores de sentiment en train:\")\n",
    "print(df_train['Sentiment'].value_counts())\n",
    "\n",
    "print(\"Contando valores de sentiment en test:\")\n",
    "print(df_test['Sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un mapeo de \"Extremely Positive\" a \"Positive\" y de \"Extremely Negative\" a \"Negative\", ya que queremos simplificar el problema a tres categorías: \"Positive\", \"Negative\" y \"Neutral\". Para ello, utilizamos la función replace() de pandas para reemplazar los valores en la columna \"sentiment\". A continuación, visualizamos la distribución de las etiquetas de sentimiento en la base de datos después del mapeo con ayuda de un gráfico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Extremely Positive': 'Positive',\n",
    "    'Extremely Negative': 'Negative',\n",
    "    'Positive': 'Positive',\n",
    "    'Negative': 'Negative',\n",
    "    'Neutral': 'Neutral'\n",
    "}\n",
    "\n",
    "df_train['Sentiment'] = df_train['Sentiment'].map(mapping)\n",
    "df_test['Sentiment'] = df_test['Sentiment'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y validación\n",
    "Es momento de definir el modelo sobre el que se hará fine-tuning: `paraphrase-MiniLM-L6-v2`. Este modelo es un modelo de lenguaje preentrenado que ha sido ajustado para tareas de clasificación de texto. Utilizaremos la librería `transformers` de Hugging Face para cargar el modelo y la tokenización. A continuación, definimos la función `encode_data()` para tokenizar los tweets y convertirlos en tensores.\n",
    "\n",
    "Por otra parte, instanciamos el clasificador de texto `Transformer Classifier` sobre el que haremos fine-tuning. Este clasificador concatena la salida del `SentenceTransformer` con una capa lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_train['label'] = label_encoder.fit_transform(df_train['Sentiment'])\n",
    "df_test['label'] = label_encoder.transform(df_test['Sentiment'])\n",
    "\n",
    "sent_transformer = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "classifier = Classifier(\n",
    "    sent_transformer.get_sentence_embedding_dimension(), 3\n",
    ")\n",
    "tuned_transformer = Transformer_Classifier(\n",
    "    sent_transformer, classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el fine-tuning del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch: 1/15, Step: 0/16463, Loss: 0.957538, Avg Loss: 0.958\n",
      "Epoch: 1/15, Step: 101/16463, Loss: 0.901247, Avg Loss: 1.040\n",
      "Epoch: 1/15, Step: 202/16463, Loss: 0.553357, Avg Loss: 0.975\n",
      "Epoch: 1/15, Step: 303/16463, Loss: 0.750833, Avg Loss: 0.913\n",
      "Epoch: 1/15, Step: 404/16463, Loss: 1.089126, Avg Loss: 0.845\n",
      "Epoch: 1/15, Step: 505/16463, Loss: 0.464621, Avg Loss: 0.800\n",
      "Epoch: 1/15, Step: 606/16463, Loss: 0.394423, Avg Loss: 0.786\n",
      "Epoch: 1/15, Step: 707/16463, Loss: 0.607678, Avg Loss: 0.760\n",
      "Epoch: 1/15, Step: 808/16463, Loss: 1.928690, Avg Loss: 0.748\n",
      "Epoch: 1/15, Step: 909/16463, Loss: 0.125313, Avg Loss: 0.738\n",
      "Epoch: 1/15, Step: 1010/16463, Loss: 0.828807, Avg Loss: 0.733\n",
      "Epoch: 1/15, Step: 1111/16463, Loss: 0.820307, Avg Loss: 0.728\n",
      "Epoch: 1/15, Step: 1212/16463, Loss: 0.116661, Avg Loss: 0.722\n",
      "Epoch: 1/15, Step: 1313/16463, Loss: 0.501669, Avg Loss: 0.709\n",
      "Epoch: 1/15, Step: 1414/16463, Loss: 1.430885, Avg Loss: 0.700\n",
      "Epoch: 1/15, Step: 1515/16463, Loss: 0.555222, Avg Loss: 0.689\n",
      "Epoch: 1/15, Step: 1616/16463, Loss: 1.216696, Avg Loss: 0.679\n",
      "Epoch: 1/15, Step: 1717/16463, Loss: 1.803766, Avg Loss: 0.672\n",
      "Epoch: 1/15, Step: 1818/16463, Loss: 1.433438, Avg Loss: 0.667\n",
      "Epoch: 1/15, Step: 1919/16463, Loss: 0.101635, Avg Loss: 0.659\n",
      "Epoch: 1/15, Step: 2020/16463, Loss: 0.424529, Avg Loss: 0.648\n",
      "Epoch: 1/15, Step: 2121/16463, Loss: 0.125582, Avg Loss: 0.647\n",
      "Epoch: 1/15, Step: 2222/16463, Loss: 0.060598, Avg Loss: 0.644\n",
      "Epoch: 1/15, Step: 2323/16463, Loss: 0.060756, Avg Loss: 0.638\n",
      "Epoch: 1/15, Step: 2424/16463, Loss: 1.308215, Avg Loss: 0.632\n",
      "Epoch: 1/15, Step: 2525/16463, Loss: 1.460378, Avg Loss: 0.624\n",
      "Epoch: 1/15, Step: 2626/16463, Loss: 1.391173, Avg Loss: 0.623\n",
      "Epoch: 1/15, Step: 2727/16463, Loss: 0.073307, Avg Loss: 0.619\n",
      "Epoch: 1/15, Step: 2828/16463, Loss: 0.375314, Avg Loss: 0.618\n",
      "Epoch: 1/15, Step: 2929/16463, Loss: 0.403353, Avg Loss: 0.616\n",
      "Epoch: 1/15, Step: 3030/16463, Loss: 1.174375, Avg Loss: 0.612\n",
      "Epoch: 1/15, Step: 3131/16463, Loss: 0.573035, Avg Loss: 0.610\n",
      "Epoch: 1/15, Step: 3232/16463, Loss: 0.318845, Avg Loss: 0.604\n",
      "Epoch: 1/15, Step: 3333/16463, Loss: 0.043007, Avg Loss: 0.598\n",
      "Epoch: 1/15, Step: 3434/16463, Loss: 0.014122, Avg Loss: 0.595\n",
      "Epoch: 1/15, Step: 3535/16463, Loss: 1.807684, Avg Loss: 0.591\n",
      "Epoch: 1/15, Step: 3636/16463, Loss: 1.046153, Avg Loss: 0.588\n",
      "Epoch: 1/15, Step: 3737/16463, Loss: 0.047691, Avg Loss: 0.584\n",
      "Epoch: 1/15, Step: 3838/16463, Loss: 0.233785, Avg Loss: 0.581\n",
      "Epoch: 1/15, Step: 3939/16463, Loss: 0.705604, Avg Loss: 0.579\n",
      "Epoch: 1/15, Step: 4040/16463, Loss: 0.031247, Avg Loss: 0.575\n",
      "Epoch: 1/15, Step: 4141/16463, Loss: 0.120851, Avg Loss: 0.570\n",
      "Epoch: 1/15, Step: 4242/16463, Loss: 0.211905, Avg Loss: 0.566\n",
      "Epoch: 1/15, Step: 4343/16463, Loss: 0.049941, Avg Loss: 0.566\n",
      "Epoch: 1/15, Step: 4444/16463, Loss: 0.373099, Avg Loss: 0.565\n",
      "Epoch: 1/15, Step: 4545/16463, Loss: 1.026934, Avg Loss: 0.563\n",
      "Epoch: 1/15, Step: 4646/16463, Loss: 0.159904, Avg Loss: 0.561\n",
      "Epoch: 1/15, Step: 4747/16463, Loss: 0.069145, Avg Loss: 0.557\n",
      "Epoch: 1/15, Step: 4848/16463, Loss: 0.035217, Avg Loss: 0.555\n",
      "Epoch: 1/15, Step: 4949/16463, Loss: 0.242430, Avg Loss: 0.551\n",
      "Epoch: 1/15, Step: 5050/16463, Loss: 0.420380, Avg Loss: 0.550\n",
      "Epoch: 1/15, Step: 5151/16463, Loss: 0.159730, Avg Loss: 0.546\n",
      "Epoch: 1/15, Step: 5252/16463, Loss: 1.352119, Avg Loss: 0.545\n",
      "Epoch: 1/15, Step: 5353/16463, Loss: 0.096052, Avg Loss: 0.542\n",
      "Epoch: 1/15, Step: 5454/16463, Loss: 0.480610, Avg Loss: 0.541\n",
      "Epoch: 1/15, Step: 5555/16463, Loss: 0.377549, Avg Loss: 0.537\n",
      "Epoch: 1/15, Step: 5656/16463, Loss: 0.623400, Avg Loss: 0.536\n",
      "Epoch: 1/15, Step: 5757/16463, Loss: 2.241660, Avg Loss: 0.533\n",
      "Epoch: 1/15, Step: 5858/16463, Loss: 0.016707, Avg Loss: 0.531\n",
      "Epoch: 1/15, Step: 5959/16463, Loss: 0.072987, Avg Loss: 0.529\n",
      "Epoch: 1/15, Step: 6060/16463, Loss: 0.219461, Avg Loss: 0.528\n",
      "Epoch: 1/15, Step: 6161/16463, Loss: 0.072513, Avg Loss: 0.527\n",
      "Epoch: 1/15, Step: 6262/16463, Loss: 0.018811, Avg Loss: 0.524\n",
      "Epoch: 1/15, Step: 6363/16463, Loss: 0.006498, Avg Loss: 0.522\n",
      "Epoch: 1/15, Step: 6464/16463, Loss: 1.740552, Avg Loss: 0.520\n",
      "Epoch: 1/15, Step: 6565/16463, Loss: 0.088103, Avg Loss: 0.519\n",
      "Epoch: 1/15, Step: 6666/16463, Loss: 0.059754, Avg Loss: 0.517\n",
      "Epoch: 1/15, Step: 6767/16463, Loss: 0.008738, Avg Loss: 0.516\n",
      "Epoch: 1/15, Step: 6868/16463, Loss: 0.197719, Avg Loss: 0.514\n",
      "Epoch: 1/15, Step: 6969/16463, Loss: 0.229616, Avg Loss: 0.513\n",
      "Epoch: 1/15, Step: 7070/16463, Loss: 0.087205, Avg Loss: 0.513\n",
      "Epoch: 1/15, Step: 7171/16463, Loss: 1.425442, Avg Loss: 0.511\n",
      "Epoch: 1/15, Step: 7272/16463, Loss: 0.596698, Avg Loss: 0.509\n",
      "Epoch: 1/15, Step: 7373/16463, Loss: 0.228003, Avg Loss: 0.508\n",
      "Epoch: 1/15, Step: 7474/16463, Loss: 0.055682, Avg Loss: 0.507\n",
      "Epoch: 1/15, Step: 7575/16463, Loss: 0.009228, Avg Loss: 0.504\n",
      "Epoch: 1/15, Step: 7676/16463, Loss: 0.008852, Avg Loss: 0.502\n",
      "Epoch: 1/15, Step: 7777/16463, Loss: 0.648645, Avg Loss: 0.501\n",
      "Epoch: 1/15, Step: 7878/16463, Loss: 0.550351, Avg Loss: 0.499\n",
      "Epoch: 1/15, Step: 7979/16463, Loss: 0.009308, Avg Loss: 0.497\n",
      "Epoch: 1/15, Step: 8080/16463, Loss: 0.041474, Avg Loss: 0.496\n",
      "Epoch: 1/15, Step: 8181/16463, Loss: 0.036888, Avg Loss: 0.495\n",
      "Epoch: 1/15, Step: 8282/16463, Loss: 1.320117, Avg Loss: 0.493\n",
      "Epoch: 1/15, Step: 8383/16463, Loss: 0.089054, Avg Loss: 0.491\n",
      "Epoch: 1/15, Step: 8484/16463, Loss: 0.496082, Avg Loss: 0.491\n",
      "Epoch: 1/15, Step: 8585/16463, Loss: 0.382979, Avg Loss: 0.490\n",
      "Epoch: 1/15, Step: 8686/16463, Loss: 0.053745, Avg Loss: 0.489\n",
      "Epoch: 1/15, Step: 8787/16463, Loss: 0.335096, Avg Loss: 0.487\n",
      "Epoch: 1/15, Step: 8888/16463, Loss: 0.045679, Avg Loss: 0.487\n",
      "Epoch: 1/15, Step: 8989/16463, Loss: 0.834304, Avg Loss: 0.486\n",
      "Epoch: 1/15, Step: 9090/16463, Loss: 0.008748, Avg Loss: 0.485\n",
      "Epoch: 1/15, Step: 9191/16463, Loss: 0.195606, Avg Loss: 0.484\n",
      "Epoch: 1/15, Step: 9292/16463, Loss: 0.046430, Avg Loss: 0.483\n",
      "Epoch: 1/15, Step: 9393/16463, Loss: 1.589896, Avg Loss: 0.483\n",
      "Epoch: 1/15, Step: 9494/16463, Loss: 0.044595, Avg Loss: 0.482\n",
      "Epoch: 1/15, Step: 9595/16463, Loss: 1.078788, Avg Loss: 0.480\n",
      "Epoch: 1/15, Step: 9696/16463, Loss: 0.352085, Avg Loss: 0.479\n",
      "Epoch: 1/15, Step: 9797/16463, Loss: 0.284243, Avg Loss: 0.478\n",
      "Epoch: 1/15, Step: 9898/16463, Loss: 0.018310, Avg Loss: 0.477\n",
      "Epoch: 1/15, Step: 9999/16463, Loss: 0.086258, Avg Loss: 0.475\n",
      "Epoch: 1/15, Step: 10100/16463, Loss: 0.066787, Avg Loss: 0.473\n",
      "Epoch: 1/15, Step: 10201/16463, Loss: 1.081445, Avg Loss: 0.472\n",
      "Epoch: 1/15, Step: 10302/16463, Loss: 0.030401, Avg Loss: 0.471\n",
      "Epoch: 1/15, Step: 10403/16463, Loss: 3.881816, Avg Loss: 0.470\n",
      "Epoch: 1/15, Step: 10504/16463, Loss: 0.081357, Avg Loss: 0.469\n",
      "Epoch: 1/15, Step: 10605/16463, Loss: 0.504986, Avg Loss: 0.467\n",
      "Epoch: 1/15, Step: 10706/16463, Loss: 0.217166, Avg Loss: 0.466\n",
      "Epoch: 1/15, Step: 10807/16463, Loss: 0.146816, Avg Loss: 0.465\n",
      "Epoch: 1/15, Step: 10908/16463, Loss: 0.017812, Avg Loss: 0.464\n",
      "Epoch: 1/15, Step: 11009/16463, Loss: 0.840927, Avg Loss: 0.463\n",
      "Epoch: 1/15, Step: 11110/16463, Loss: 0.024556, Avg Loss: 0.462\n",
      "Epoch: 1/15, Step: 11211/16463, Loss: 1.545641, Avg Loss: 0.461\n",
      "Epoch: 1/15, Step: 11312/16463, Loss: 0.167412, Avg Loss: 0.460\n",
      "Epoch: 1/15, Step: 11413/16463, Loss: 0.468983, Avg Loss: 0.459\n",
      "Epoch: 1/15, Step: 11514/16463, Loss: 0.087008, Avg Loss: 0.457\n",
      "Epoch: 1/15, Step: 11615/16463, Loss: 0.709428, Avg Loss: 0.457\n",
      "Epoch: 1/15, Step: 11716/16463, Loss: 0.459720, Avg Loss: 0.456\n",
      "Epoch: 1/15, Step: 11817/16463, Loss: 0.938248, Avg Loss: 0.454\n",
      "Epoch: 1/15, Step: 11918/16463, Loss: 0.122395, Avg Loss: 0.453\n",
      "Epoch: 1/15, Step: 12019/16463, Loss: 0.505321, Avg Loss: 0.452\n",
      "Epoch: 1/15, Step: 12120/16463, Loss: 0.423101, Avg Loss: 0.452\n",
      "Epoch: 1/15, Step: 12221/16463, Loss: 0.732408, Avg Loss: 0.451\n",
      "Epoch: 1/15, Step: 12322/16463, Loss: 0.454985, Avg Loss: 0.450\n",
      "Epoch: 1/15, Step: 12423/16463, Loss: 0.141920, Avg Loss: 0.450\n",
      "Epoch: 1/15, Step: 12524/16463, Loss: 0.029070, Avg Loss: 0.449\n",
      "Epoch: 1/15, Step: 12625/16463, Loss: 0.162993, Avg Loss: 0.448\n",
      "Epoch: 1/15, Step: 12726/16463, Loss: 0.262891, Avg Loss: 0.446\n",
      "Epoch: 1/15, Step: 12827/16463, Loss: 0.246969, Avg Loss: 0.446\n",
      "Epoch: 1/15, Step: 12928/16463, Loss: 0.070005, Avg Loss: 0.445\n",
      "Epoch: 1/15, Step: 13029/16463, Loss: 0.013284, Avg Loss: 0.444\n",
      "Epoch: 1/15, Step: 13130/16463, Loss: 0.027087, Avg Loss: 0.443\n",
      "Epoch: 1/15, Step: 13231/16463, Loss: 0.043120, Avg Loss: 0.441\n",
      "Epoch: 1/15, Step: 13332/16463, Loss: 0.179539, Avg Loss: 0.440\n",
      "Epoch: 1/15, Step: 13433/16463, Loss: 0.024229, Avg Loss: 0.440\n",
      "Epoch: 1/15, Step: 13534/16463, Loss: 0.420715, Avg Loss: 0.439\n",
      "Epoch: 1/15, Step: 13635/16463, Loss: 0.034188, Avg Loss: 0.437\n",
      "Epoch: 1/15, Step: 13736/16463, Loss: 0.345914, Avg Loss: 0.437\n",
      "Epoch: 1/15, Step: 13837/16463, Loss: 0.337261, Avg Loss: 0.437\n",
      "Epoch: 1/15, Step: 13938/16463, Loss: 0.199187, Avg Loss: 0.435\n",
      "Epoch: 1/15, Step: 14039/16463, Loss: 0.025931, Avg Loss: 0.435\n",
      "Epoch: 1/15, Step: 14140/16463, Loss: 0.035525, Avg Loss: 0.435\n",
      "Epoch: 1/15, Step: 14241/16463, Loss: 0.010108, Avg Loss: 0.434\n",
      "Epoch: 1/15, Step: 14342/16463, Loss: 0.192687, Avg Loss: 0.434\n",
      "Epoch: 1/15, Step: 14443/16463, Loss: 0.036054, Avg Loss: 0.433\n",
      "Epoch: 1/15, Step: 14544/16463, Loss: 0.039056, Avg Loss: 0.432\n",
      "Epoch: 1/15, Step: 14645/16463, Loss: 0.691485, Avg Loss: 0.431\n",
      "Epoch: 1/15, Step: 14746/16463, Loss: 0.165393, Avg Loss: 0.431\n",
      "Epoch: 1/15, Step: 14847/16463, Loss: 0.019664, Avg Loss: 0.430\n",
      "Epoch: 1/15, Step: 14948/16463, Loss: 1.527489, Avg Loss: 0.429\n",
      "Epoch: 1/15, Step: 15049/16463, Loss: 0.014739, Avg Loss: 0.428\n",
      "Epoch: 1/15, Step: 15150/16463, Loss: 0.028488, Avg Loss: 0.427\n",
      "Epoch: 1/15, Step: 15251/16463, Loss: 0.715700, Avg Loss: 0.426\n",
      "Epoch: 1/15, Step: 15352/16463, Loss: 0.903664, Avg Loss: 0.425\n",
      "Epoch: 1/15, Step: 15453/16463, Loss: 0.223437, Avg Loss: 0.425\n",
      "Epoch: 1/15, Step: 15554/16463, Loss: 0.042442, Avg Loss: 0.424\n",
      "Epoch: 1/15, Step: 15655/16463, Loss: 0.005857, Avg Loss: 0.423\n",
      "Epoch: 1/15, Step: 15756/16463, Loss: 2.609909, Avg Loss: 0.423\n",
      "Epoch: 1/15, Step: 15857/16463, Loss: 0.039554, Avg Loss: 0.423\n",
      "Epoch: 1/15, Step: 15958/16463, Loss: 0.069967, Avg Loss: 0.422\n",
      "Epoch: 1/15, Step: 16059/16463, Loss: 0.031992, Avg Loss: 0.422\n",
      "Epoch: 1/15, Step: 16160/16463, Loss: 0.025902, Avg Loss: 0.421\n",
      "Epoch: 1/15, Step: 16261/16463, Loss: 0.225958, Avg Loss: 0.421\n",
      "Epoch: 1/15, Step: 16362/16463, Loss: 1.723143, Avg Loss: 0.420\n",
      "Epoch 1/15, Training Loss: 0.4191\n",
      "Validation Accuracy: 0.8958\n",
      "New best model found with accuracy: 0.8958. Saving model...\n",
      "Model saved.\n",
      "Epoch: 2/15, Step: 0/16463, Loss: 0.158357, Avg Loss: 0.158\n",
      "Epoch: 2/15, Step: 101/16463, Loss: 0.499041, Avg Loss: 0.311\n",
      "Epoch: 2/15, Step: 202/16463, Loss: 0.264158, Avg Loss: 0.294\n",
      "Epoch: 2/15, Step: 303/16463, Loss: 0.033485, Avg Loss: 0.260\n",
      "Epoch: 2/15, Step: 404/16463, Loss: 0.027215, Avg Loss: 0.249\n",
      "Epoch: 2/15, Step: 505/16463, Loss: 0.103068, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 606/16463, Loss: 0.006014, Avg Loss: 0.260\n",
      "Epoch: 2/15, Step: 707/16463, Loss: 0.023289, Avg Loss: 0.262\n",
      "Epoch: 2/15, Step: 808/16463, Loss: 0.429622, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 909/16463, Loss: 0.010161, Avg Loss: 0.268\n",
      "Epoch: 2/15, Step: 1010/16463, Loss: 0.056295, Avg Loss: 0.265\n",
      "Epoch: 2/15, Step: 1111/16463, Loss: 0.018811, Avg Loss: 0.274\n",
      "Epoch: 2/15, Step: 1212/16463, Loss: 0.005144, Avg Loss: 0.277\n",
      "Epoch: 2/15, Step: 1313/16463, Loss: 0.779346, Avg Loss: 0.274\n",
      "Epoch: 2/15, Step: 1414/16463, Loss: 0.012287, Avg Loss: 0.272\n",
      "Epoch: 2/15, Step: 1515/16463, Loss: 0.419043, Avg Loss: 0.268\n",
      "Epoch: 2/15, Step: 1616/16463, Loss: 0.002628, Avg Loss: 0.265\n",
      "Epoch: 2/15, Step: 1717/16463, Loss: 1.053716, Avg Loss: 0.261\n",
      "Epoch: 2/15, Step: 1818/16463, Loss: 0.274543, Avg Loss: 0.267\n",
      "Epoch: 2/15, Step: 1919/16463, Loss: 0.074419, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 2020/16463, Loss: 0.025057, Avg Loss: 0.267\n",
      "Epoch: 2/15, Step: 2121/16463, Loss: 0.063264, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 2222/16463, Loss: 0.068983, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 2323/16463, Loss: 0.362839, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 2424/16463, Loss: 1.493425, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 2525/16463, Loss: 0.161071, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 2626/16463, Loss: 0.038470, Avg Loss: 0.270\n",
      "Epoch: 2/15, Step: 2727/16463, Loss: 0.049979, Avg Loss: 0.269\n",
      "Epoch: 2/15, Step: 2828/16463, Loss: 0.024666, Avg Loss: 0.270\n",
      "Epoch: 2/15, Step: 2929/16463, Loss: 0.046389, Avg Loss: 0.268\n",
      "Epoch: 2/15, Step: 3030/16463, Loss: 0.012894, Avg Loss: 0.266\n",
      "Epoch: 2/15, Step: 3131/16463, Loss: 0.006752, Avg Loss: 0.264\n",
      "Epoch: 2/15, Step: 3232/16463, Loss: 0.037428, Avg Loss: 0.262\n",
      "Epoch: 2/15, Step: 3333/16463, Loss: 0.579735, Avg Loss: 0.260\n",
      "Epoch: 2/15, Step: 3434/16463, Loss: 0.029303, Avg Loss: 0.260\n",
      "Epoch: 2/15, Step: 3535/16463, Loss: 1.539665, Avg Loss: 0.258\n",
      "Epoch: 2/15, Step: 3636/16463, Loss: 0.074934, Avg Loss: 0.258\n",
      "Epoch: 2/15, Step: 3737/16463, Loss: 0.012252, Avg Loss: 0.257\n",
      "Epoch: 2/15, Step: 3838/16463, Loss: 0.004904, Avg Loss: 0.257\n",
      "Epoch: 2/15, Step: 3939/16463, Loss: 0.082849, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 4040/16463, Loss: 0.032664, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 4141/16463, Loss: 0.007981, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 4242/16463, Loss: 0.003610, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 4343/16463, Loss: 0.252365, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 4444/16463, Loss: 0.182574, Avg Loss: 0.252\n",
      "Epoch: 2/15, Step: 4545/16463, Loss: 0.194278, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 4646/16463, Loss: 0.039424, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 4747/16463, Loss: 0.019178, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 4848/16463, Loss: 0.001131, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 4949/16463, Loss: 0.024607, Avg Loss: 0.252\n",
      "Epoch: 2/15, Step: 5050/16463, Loss: 0.010903, Avg Loss: 0.251\n",
      "Epoch: 2/15, Step: 5151/16463, Loss: 1.731165, Avg Loss: 0.252\n",
      "Epoch: 2/15, Step: 5252/16463, Loss: 1.625002, Avg Loss: 0.251\n",
      "Epoch: 2/15, Step: 5353/16463, Loss: 0.985809, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 5454/16463, Loss: 0.003382, Avg Loss: 0.252\n",
      "Epoch: 2/15, Step: 5555/16463, Loss: 0.004734, Avg Loss: 0.252\n",
      "Epoch: 2/15, Step: 5656/16463, Loss: 0.556807, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 5757/16463, Loss: 0.249193, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 5858/16463, Loss: 0.936133, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 5959/16463, Loss: 0.138742, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 6060/16463, Loss: 1.127605, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 6161/16463, Loss: 0.258716, Avg Loss: 0.256\n",
      "Epoch: 2/15, Step: 6262/16463, Loss: 1.693271, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 6363/16463, Loss: 0.177403, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 6464/16463, Loss: 0.374880, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 6565/16463, Loss: 0.020719, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 6666/16463, Loss: 0.078477, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 6767/16463, Loss: 0.149990, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 6868/16463, Loss: 0.002342, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 6969/16463, Loss: 0.014330, Avg Loss: 0.256\n",
      "Epoch: 2/15, Step: 7070/16463, Loss: 0.346805, Avg Loss: 0.255\n",
      "Epoch: 2/15, Step: 7171/16463, Loss: 0.439103, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 7272/16463, Loss: 0.009585, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 7373/16463, Loss: 0.022598, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 7474/16463, Loss: 0.007679, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 7575/16463, Loss: 0.003125, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 7676/16463, Loss: 0.003125, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 7777/16463, Loss: 0.097531, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 7878/16463, Loss: 0.047527, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 7979/16463, Loss: 0.014887, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 8080/16463, Loss: 0.019223, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 8181/16463, Loss: 0.724256, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 8282/16463, Loss: 0.025136, Avg Loss: 0.254\n",
      "Epoch: 2/15, Step: 8383/16463, Loss: 0.068028, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 8484/16463, Loss: 0.006429, Avg Loss: 0.253\n",
      "Epoch: 2/15, Step: 8585/16463, Loss: 0.395208, Avg Loss: 0.252\n",
      "Epoch: 2/15, Step: 8686/16463, Loss: 0.008277, Avg Loss: 0.252\n",
      "Epoch: 2/15, Step: 8787/16463, Loss: 0.128486, Avg Loss: 0.251\n",
      "Epoch: 2/15, Step: 8888/16463, Loss: 0.198545, Avg Loss: 0.251\n",
      "Epoch: 2/15, Step: 8989/16463, Loss: 0.286874, Avg Loss: 0.251\n",
      "Epoch: 2/15, Step: 9090/16463, Loss: 0.042947, Avg Loss: 0.251\n",
      "Epoch: 2/15, Step: 9191/16463, Loss: 0.011630, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 9292/16463, Loss: 0.017323, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 9393/16463, Loss: 0.085839, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 9494/16463, Loss: 0.186558, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 9595/16463, Loss: 0.109107, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 9696/16463, Loss: 0.005201, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 9797/16463, Loss: 0.009755, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 9898/16463, Loss: 0.443445, Avg Loss: 0.251\n",
      "Epoch: 2/15, Step: 9999/16463, Loss: 0.008519, Avg Loss: 0.250\n",
      "Epoch: 2/15, Step: 10100/16463, Loss: 0.883331, Avg Loss: 0.249\n",
      "Epoch: 2/15, Step: 10201/16463, Loss: 0.035482, Avg Loss: 0.249\n",
      "Epoch: 2/15, Step: 10302/16463, Loss: 0.292814, Avg Loss: 0.249\n",
      "Epoch: 2/15, Step: 10403/16463, Loss: 0.007223, Avg Loss: 0.248\n",
      "Epoch: 2/15, Step: 10504/16463, Loss: 0.885390, Avg Loss: 0.247\n",
      "Epoch: 2/15, Step: 10605/16463, Loss: 0.014254, Avg Loss: 0.247\n",
      "Epoch: 2/15, Step: 10706/16463, Loss: 0.021953, Avg Loss: 0.246\n",
      "Epoch: 2/15, Step: 10807/16463, Loss: 0.695753, Avg Loss: 0.246\n",
      "Epoch: 2/15, Step: 10908/16463, Loss: 1.048497, Avg Loss: 0.246\n",
      "Epoch: 2/15, Step: 11009/16463, Loss: 0.005815, Avg Loss: 0.245\n",
      "Epoch: 2/15, Step: 11110/16463, Loss: 0.054471, Avg Loss: 0.245\n",
      "Epoch: 2/15, Step: 11211/16463, Loss: 0.002390, Avg Loss: 0.244\n",
      "Epoch: 2/15, Step: 11312/16463, Loss: 0.006774, Avg Loss: 0.244\n",
      "Epoch: 2/15, Step: 11413/16463, Loss: 0.071520, Avg Loss: 0.245\n",
      "Epoch: 2/15, Step: 11514/16463, Loss: 0.003254, Avg Loss: 0.244\n",
      "Epoch: 2/15, Step: 11615/16463, Loss: 0.017950, Avg Loss: 0.244\n",
      "Epoch: 2/15, Step: 11716/16463, Loss: 0.004073, Avg Loss: 0.244\n",
      "Epoch: 2/15, Step: 11817/16463, Loss: 0.022112, Avg Loss: 0.244\n",
      "Epoch: 2/15, Step: 11918/16463, Loss: 0.001707, Avg Loss: 0.243\n",
      "Epoch: 2/15, Step: 12019/16463, Loss: 0.820580, Avg Loss: 0.243\n",
      "Epoch: 2/15, Step: 12120/16463, Loss: 0.112115, Avg Loss: 0.243\n",
      "Epoch: 2/15, Step: 12221/16463, Loss: 0.095995, Avg Loss: 0.243\n",
      "Epoch: 2/15, Step: 12322/16463, Loss: 0.164533, Avg Loss: 0.242\n",
      "Epoch: 2/15, Step: 12423/16463, Loss: 0.004911, Avg Loss: 0.242\n",
      "Epoch: 2/15, Step: 12524/16463, Loss: 0.006809, Avg Loss: 0.242\n",
      "Epoch: 2/15, Step: 12625/16463, Loss: 0.139896, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 12726/16463, Loss: 0.066065, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 12827/16463, Loss: 0.003545, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 12928/16463, Loss: 0.002706, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13029/16463, Loss: 0.014220, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13130/16463, Loss: 0.013122, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13231/16463, Loss: 0.045094, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13332/16463, Loss: 0.006780, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13433/16463, Loss: 0.024292, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13534/16463, Loss: 0.027690, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13635/16463, Loss: 0.270773, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13736/16463, Loss: 0.005733, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13837/16463, Loss: 0.040367, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 13938/16463, Loss: 0.978670, Avg Loss: 0.241\n",
      "Epoch: 2/15, Step: 14039/16463, Loss: 0.010611, Avg Loss: 0.240\n",
      "Epoch: 2/15, Step: 14140/16463, Loss: 0.033255, Avg Loss: 0.240\n",
      "Epoch: 2/15, Step: 14241/16463, Loss: 0.068253, Avg Loss: 0.240\n",
      "Epoch: 2/15, Step: 14342/16463, Loss: 0.004398, Avg Loss: 0.240\n",
      "Epoch: 2/15, Step: 14443/16463, Loss: 0.359375, Avg Loss: 0.240\n",
      "Epoch: 2/15, Step: 14544/16463, Loss: 0.030561, Avg Loss: 0.240\n",
      "Epoch: 2/15, Step: 14645/16463, Loss: 0.571592, Avg Loss: 0.240\n",
      "Epoch: 2/15, Step: 14746/16463, Loss: 0.034147, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 14847/16463, Loss: 0.049321, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 14948/16463, Loss: 0.003433, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 15049/16463, Loss: 0.040309, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 15150/16463, Loss: 0.815065, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 15251/16463, Loss: 0.029936, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 15352/16463, Loss: 0.084044, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 15453/16463, Loss: 0.017837, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 15554/16463, Loss: 0.145807, Avg Loss: 0.239\n",
      "Epoch: 2/15, Step: 15655/16463, Loss: 0.005269, Avg Loss: 0.238\n",
      "Epoch: 2/15, Step: 15756/16463, Loss: 0.019346, Avg Loss: 0.238\n",
      "Epoch: 2/15, Step: 15857/16463, Loss: 0.001400, Avg Loss: 0.238\n",
      "Epoch: 2/15, Step: 15958/16463, Loss: 0.001998, Avg Loss: 0.237\n",
      "Epoch: 2/15, Step: 16059/16463, Loss: 0.008389, Avg Loss: 0.237\n",
      "Epoch: 2/15, Step: 16160/16463, Loss: 0.009094, Avg Loss: 0.237\n",
      "Epoch: 2/15, Step: 16261/16463, Loss: 1.159120, Avg Loss: 0.237\n",
      "Epoch: 2/15, Step: 16362/16463, Loss: 0.033468, Avg Loss: 0.236\n",
      "Epoch 2/15, Training Loss: 0.2362\n",
      "Validation Accuracy: 0.9155\n",
      "New best model found with accuracy: 0.9155. Saving model...\n",
      "Model saved.\n",
      "Epoch: 3/15, Step: 0/16463, Loss: 0.016046, Avg Loss: 0.016\n",
      "Epoch: 3/15, Step: 101/16463, Loss: 0.005765, Avg Loss: 0.078\n",
      "Epoch: 3/15, Step: 202/16463, Loss: 0.002155, Avg Loss: 0.096\n",
      "Epoch: 3/15, Step: 303/16463, Loss: 0.020276, Avg Loss: 0.118\n",
      "Epoch: 3/15, Step: 404/16463, Loss: 0.015710, Avg Loss: 0.122\n",
      "Epoch: 3/15, Step: 505/16463, Loss: 0.002689, Avg Loss: 0.128\n",
      "Epoch: 3/15, Step: 606/16463, Loss: 0.002806, Avg Loss: 0.137\n",
      "Epoch: 3/15, Step: 707/16463, Loss: 0.001929, Avg Loss: 0.146\n",
      "Epoch: 3/15, Step: 808/16463, Loss: 0.006258, Avg Loss: 0.151\n",
      "Epoch: 3/15, Step: 909/16463, Loss: 2.368750, Avg Loss: 0.152\n",
      "Epoch: 3/15, Step: 1010/16463, Loss: 0.003665, Avg Loss: 0.151\n",
      "Epoch: 3/15, Step: 1111/16463, Loss: 0.095802, Avg Loss: 0.156\n",
      "Epoch: 3/15, Step: 1212/16463, Loss: 0.195473, Avg Loss: 0.157\n",
      "Epoch: 3/15, Step: 1313/16463, Loss: 0.427522, Avg Loss: 0.155\n",
      "Epoch: 3/15, Step: 1414/16463, Loss: 0.002914, Avg Loss: 0.155\n",
      "Epoch: 3/15, Step: 1515/16463, Loss: 0.154862, Avg Loss: 0.156\n",
      "Epoch: 3/15, Step: 1616/16463, Loss: 0.019308, Avg Loss: 0.157\n",
      "Epoch: 3/15, Step: 1717/16463, Loss: 0.002908, Avg Loss: 0.154\n",
      "Epoch: 3/15, Step: 1818/16463, Loss: 0.172731, Avg Loss: 0.156\n",
      "Epoch: 3/15, Step: 1919/16463, Loss: 0.007644, Avg Loss: 0.160\n",
      "Epoch: 3/15, Step: 2020/16463, Loss: 0.003433, Avg Loss: 0.158\n",
      "Epoch: 3/15, Step: 2121/16463, Loss: 0.301299, Avg Loss: 0.157\n",
      "Epoch: 3/15, Step: 2222/16463, Loss: 0.040274, Avg Loss: 0.155\n",
      "Epoch: 3/15, Step: 2323/16463, Loss: 0.002180, Avg Loss: 0.155\n",
      "Epoch: 3/15, Step: 2424/16463, Loss: 0.004330, Avg Loss: 0.154\n",
      "Epoch: 3/15, Step: 2525/16463, Loss: 0.033559, Avg Loss: 0.153\n",
      "Epoch: 3/15, Step: 2626/16463, Loss: 1.034571, Avg Loss: 0.158\n",
      "Epoch: 3/15, Step: 2727/16463, Loss: 0.001211, Avg Loss: 0.156\n",
      "Epoch: 3/15, Step: 2828/16463, Loss: 0.002484, Avg Loss: 0.155\n",
      "Epoch: 3/15, Step: 2929/16463, Loss: 0.015862, Avg Loss: 0.155\n",
      "Epoch: 3/15, Step: 3030/16463, Loss: 0.002209, Avg Loss: 0.156\n",
      "Epoch: 3/15, Step: 3131/16463, Loss: 0.009488, Avg Loss: 0.160\n",
      "Epoch: 3/15, Step: 3232/16463, Loss: 1.701959, Avg Loss: 0.160\n",
      "Epoch: 3/15, Step: 3333/16463, Loss: 0.071127, Avg Loss: 0.159\n",
      "Epoch: 3/15, Step: 3434/16463, Loss: 0.069118, Avg Loss: 0.160\n",
      "Epoch: 3/15, Step: 3535/16463, Loss: 0.031198, Avg Loss: 0.159\n",
      "Epoch: 3/15, Step: 3636/16463, Loss: 0.007770, Avg Loss: 0.161\n",
      "Epoch: 3/15, Step: 3737/16463, Loss: 0.003740, Avg Loss: 0.158\n",
      "Epoch: 3/15, Step: 3838/16463, Loss: 0.041860, Avg Loss: 0.158\n",
      "Epoch: 3/15, Step: 3939/16463, Loss: 0.020093, Avg Loss: 0.159\n",
      "Epoch: 3/15, Step: 4040/16463, Loss: 0.684499, Avg Loss: 0.159\n",
      "Epoch: 3/15, Step: 4141/16463, Loss: 0.568171, Avg Loss: 0.160\n",
      "Epoch: 3/15, Step: 4242/16463, Loss: 0.002557, Avg Loss: 0.159\n",
      "Epoch: 3/15, Step: 4343/16463, Loss: 0.003012, Avg Loss: 0.159\n",
      "Epoch: 3/15, Step: 4444/16463, Loss: 0.025501, Avg Loss: 0.159\n",
      "Epoch: 3/15, Step: 4545/16463, Loss: 0.045149, Avg Loss: 0.160\n",
      "Epoch: 3/15, Step: 4646/16463, Loss: 0.020871, Avg Loss: 0.160\n",
      "Epoch: 3/15, Step: 4747/16463, Loss: 0.005760, Avg Loss: 0.161\n",
      "Epoch: 3/15, Step: 4848/16463, Loss: 0.003204, Avg Loss: 0.161\n",
      "Epoch: 3/15, Step: 4949/16463, Loss: 1.082361, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 5050/16463, Loss: 0.001400, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 5151/16463, Loss: 0.902865, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 5252/16463, Loss: 0.537918, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 5353/16463, Loss: 0.533206, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 5454/16463, Loss: 0.145123, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 5555/16463, Loss: 0.004777, Avg Loss: 0.167\n",
      "Epoch: 3/15, Step: 5656/16463, Loss: 0.016654, Avg Loss: 0.167\n",
      "Epoch: 3/15, Step: 5757/16463, Loss: 0.002717, Avg Loss: 0.167\n",
      "Epoch: 3/15, Step: 5858/16463, Loss: 0.001666, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 5959/16463, Loss: 0.118907, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 6060/16463, Loss: 0.017154, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 6161/16463, Loss: 0.001719, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 6262/16463, Loss: 0.151642, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 6363/16463, Loss: 1.402727, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 6464/16463, Loss: 0.019417, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 6565/16463, Loss: 0.006457, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 6666/16463, Loss: 0.027590, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 6767/16463, Loss: 0.004061, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 6868/16463, Loss: 0.738417, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 6969/16463, Loss: 0.002953, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 7070/16463, Loss: 1.352499, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 7171/16463, Loss: 0.003705, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 7272/16463, Loss: 0.006798, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 7373/16463, Loss: 0.147739, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 7474/16463, Loss: 0.061927, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 7575/16463, Loss: 0.001432, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 7676/16463, Loss: 0.057993, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 7777/16463, Loss: 0.070870, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 7878/16463, Loss: 0.002677, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 7979/16463, Loss: 0.189334, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 8080/16463, Loss: 0.034494, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 8181/16463, Loss: 0.006315, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 8282/16463, Loss: 0.003186, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 8383/16463, Loss: 0.663746, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 8484/16463, Loss: 0.184327, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 8585/16463, Loss: 0.009538, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 8686/16463, Loss: 0.017184, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 8787/16463, Loss: 0.040754, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 8888/16463, Loss: 0.008598, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 8989/16463, Loss: 0.001407, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 9090/16463, Loss: 0.189936, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 9191/16463, Loss: 0.001661, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 9292/16463, Loss: 0.011660, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 9393/16463, Loss: 0.001300, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 9494/16463, Loss: 0.005951, Avg Loss: 0.162\n",
      "Epoch: 3/15, Step: 9595/16463, Loss: 0.040971, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 9696/16463, Loss: 0.538896, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 9797/16463, Loss: 0.005772, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 9898/16463, Loss: 1.784809, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 9999/16463, Loss: 0.006843, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 10100/16463, Loss: 0.007935, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 10201/16463, Loss: 0.013673, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 10302/16463, Loss: 0.003256, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 10403/16463, Loss: 0.003565, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 10504/16463, Loss: 0.324193, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 10605/16463, Loss: 0.004112, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 10706/16463, Loss: 0.011168, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 10807/16463, Loss: 0.005845, Avg Loss: 0.163\n",
      "Epoch: 3/15, Step: 10908/16463, Loss: 0.042338, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 11009/16463, Loss: 0.004655, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 11110/16463, Loss: 0.118865, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 11211/16463, Loss: 0.009200, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 11312/16463, Loss: 0.007535, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 11413/16463, Loss: 0.067434, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 11514/16463, Loss: 0.003375, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 11615/16463, Loss: 0.106132, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 11716/16463, Loss: 0.001173, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 11817/16463, Loss: 0.002461, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 11918/16463, Loss: 0.088529, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12019/16463, Loss: 0.003458, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 12120/16463, Loss: 0.025609, Avg Loss: 0.166\n",
      "Epoch: 3/15, Step: 12221/16463, Loss: 0.004097, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12322/16463, Loss: 0.001487, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12423/16463, Loss: 0.073896, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12524/16463, Loss: 0.013049, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12625/16463, Loss: 0.247975, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12726/16463, Loss: 0.001348, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12827/16463, Loss: 0.016011, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 12928/16463, Loss: 0.042877, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 13029/16463, Loss: 0.030550, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 13130/16463, Loss: 0.003333, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 13231/16463, Loss: 0.002441, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 13332/16463, Loss: 0.003921, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 13433/16463, Loss: 0.003610, Avg Loss: 0.164\n",
      "Epoch: 3/15, Step: 13534/16463, Loss: 1.632198, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 13635/16463, Loss: 0.002543, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 13736/16463, Loss: 0.533588, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 13837/16463, Loss: 0.009005, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 13938/16463, Loss: 0.002451, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14039/16463, Loss: 0.004295, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14140/16463, Loss: 0.034653, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14241/16463, Loss: 0.027058, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14342/16463, Loss: 0.880612, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14443/16463, Loss: 0.313534, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14544/16463, Loss: 0.005434, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14645/16463, Loss: 0.002656, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14746/16463, Loss: 0.006986, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14847/16463, Loss: 3.122195, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 14948/16463, Loss: 0.177297, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15049/16463, Loss: 0.002791, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15150/16463, Loss: 0.095407, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15251/16463, Loss: 0.171805, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15352/16463, Loss: 0.208047, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15453/16463, Loss: 0.002351, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15554/16463, Loss: 0.002514, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15655/16463, Loss: 0.015163, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15756/16463, Loss: 0.019892, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15857/16463, Loss: 0.003250, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 15958/16463, Loss: 0.006957, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 16059/16463, Loss: 0.007070, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 16160/16463, Loss: 0.000920, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 16261/16463, Loss: 0.027829, Avg Loss: 0.165\n",
      "Epoch: 3/15, Step: 16362/16463, Loss: 0.011808, Avg Loss: 0.165\n",
      "Epoch 3/15, Training Loss: 0.1649\n",
      "Validation Accuracy: 0.9231\n",
      "New best model found with accuracy: 0.9231. Saving model...\n",
      "Model saved.\n",
      "Epoch: 4/15, Step: 0/16463, Loss: 0.002081, Avg Loss: 0.002\n",
      "Epoch: 4/15, Step: 101/16463, Loss: 0.454469, Avg Loss: 0.076\n",
      "Epoch: 4/15, Step: 202/16463, Loss: 0.393808, Avg Loss: 0.107\n",
      "Epoch: 4/15, Step: 303/16463, Loss: 0.022920, Avg Loss: 0.107\n",
      "Epoch: 4/15, Step: 404/16463, Loss: 0.016590, Avg Loss: 0.115\n",
      "Epoch: 4/15, Step: 505/16463, Loss: 1.095764, Avg Loss: 0.120\n",
      "Epoch: 4/15, Step: 606/16463, Loss: 0.001161, Avg Loss: 0.117\n",
      "Epoch: 4/15, Step: 707/16463, Loss: 0.004610, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 808/16463, Loss: 0.023788, Avg Loss: 0.123\n",
      "Epoch: 4/15, Step: 909/16463, Loss: 0.001586, Avg Loss: 0.119\n",
      "Epoch: 4/15, Step: 1010/16463, Loss: 0.021825, Avg Loss: 0.122\n",
      "Epoch: 4/15, Step: 1111/16463, Loss: 0.002936, Avg Loss: 0.121\n",
      "Epoch: 4/15, Step: 1212/16463, Loss: 0.016390, Avg Loss: 0.121\n",
      "Epoch: 4/15, Step: 1313/16463, Loss: 0.001083, Avg Loss: 0.122\n",
      "Epoch: 4/15, Step: 1414/16463, Loss: 0.005633, Avg Loss: 0.120\n",
      "Epoch: 4/15, Step: 1515/16463, Loss: 0.003085, Avg Loss: 0.121\n",
      "Epoch: 4/15, Step: 1616/16463, Loss: 0.004998, Avg Loss: 0.121\n",
      "Epoch: 4/15, Step: 1717/16463, Loss: 0.292143, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 1818/16463, Loss: 0.001887, Avg Loss: 0.123\n",
      "Epoch: 4/15, Step: 1919/16463, Loss: 0.002970, Avg Loss: 0.122\n",
      "Epoch: 4/15, Step: 2020/16463, Loss: 0.001137, Avg Loss: 0.121\n",
      "Epoch: 4/15, Step: 2121/16463, Loss: 0.001591, Avg Loss: 0.120\n",
      "Epoch: 4/15, Step: 2222/16463, Loss: 0.003128, Avg Loss: 0.119\n",
      "Epoch: 4/15, Step: 2323/16463, Loss: 0.160796, Avg Loss: 0.123\n",
      "Epoch: 4/15, Step: 2424/16463, Loss: 1.767388, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 2525/16463, Loss: 0.018334, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 2626/16463, Loss: 0.002470, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 2727/16463, Loss: 0.002022, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 2828/16463, Loss: 0.001333, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 2929/16463, Loss: 0.090567, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 3030/16463, Loss: 0.088352, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 3131/16463, Loss: 0.033981, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 3232/16463, Loss: 0.002037, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 3333/16463, Loss: 0.008474, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 3434/16463, Loss: 1.172528, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 3535/16463, Loss: 0.000920, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 3636/16463, Loss: 0.265906, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 3737/16463, Loss: 0.006638, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 3838/16463, Loss: 3.135193, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 3939/16463, Loss: 0.568949, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 4040/16463, Loss: 0.001695, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 4141/16463, Loss: 0.002452, Avg Loss: 0.123\n",
      "Epoch: 4/15, Step: 4242/16463, Loss: 0.003296, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 4343/16463, Loss: 0.004233, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 4444/16463, Loss: 0.004017, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 4545/16463, Loss: 0.730422, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 4646/16463, Loss: 0.012200, Avg Loss: 0.123\n",
      "Epoch: 4/15, Step: 4747/16463, Loss: 0.719389, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 4848/16463, Loss: 0.002726, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 4949/16463, Loss: 0.002837, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 5050/16463, Loss: 0.570395, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 5151/16463, Loss: 0.269631, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 5252/16463, Loss: 0.002756, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 5353/16463, Loss: 0.019901, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 5454/16463, Loss: 0.007319, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 5555/16463, Loss: 0.001459, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 5656/16463, Loss: 0.013198, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 5757/16463, Loss: 0.002817, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 5858/16463, Loss: 0.001311, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 5959/16463, Loss: 0.002862, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 6060/16463, Loss: 0.009284, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 6161/16463, Loss: 0.013849, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 6262/16463, Loss: 0.002009, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 6363/16463, Loss: 0.018794, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 6464/16463, Loss: 0.011023, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 6565/16463, Loss: 0.033980, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 6666/16463, Loss: 0.006960, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 6767/16463, Loss: 0.000975, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 6868/16463, Loss: 0.047444, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 6969/16463, Loss: 0.032514, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 7070/16463, Loss: 0.007367, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 7171/16463, Loss: 0.003653, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 7272/16463, Loss: 0.001097, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 7373/16463, Loss: 0.004671, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 7474/16463, Loss: 0.001783, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 7575/16463, Loss: 0.615153, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 7676/16463, Loss: 0.000648, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 7777/16463, Loss: 0.041682, Avg Loss: 0.124\n",
      "Epoch: 4/15, Step: 7878/16463, Loss: 0.009568, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 7979/16463, Loss: 0.003200, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 8080/16463, Loss: 0.762749, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8181/16463, Loss: 0.744256, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8282/16463, Loss: 0.001217, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8383/16463, Loss: 0.002270, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8484/16463, Loss: 0.006673, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 8585/16463, Loss: 0.004706, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8686/16463, Loss: 0.051879, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8787/16463, Loss: 0.151628, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8888/16463, Loss: 0.071590, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 8989/16463, Loss: 0.002536, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 9090/16463, Loss: 0.011043, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 9191/16463, Loss: 0.017750, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9292/16463, Loss: 0.002353, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9393/16463, Loss: 0.004686, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9494/16463, Loss: 0.003567, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9595/16463, Loss: 0.006809, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9696/16463, Loss: 0.006820, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9797/16463, Loss: 0.756994, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9898/16463, Loss: 0.297647, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 9999/16463, Loss: 0.050728, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 10100/16463, Loss: 0.007090, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 10201/16463, Loss: 0.015470, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 10302/16463, Loss: 0.003356, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 10403/16463, Loss: 0.008169, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 10504/16463, Loss: 0.069368, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 10605/16463, Loss: 0.001470, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 10706/16463, Loss: 0.047455, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 10807/16463, Loss: 0.005056, Avg Loss: 0.130\n",
      "Epoch: 4/15, Step: 10908/16463, Loss: 0.011731, Avg Loss: 0.130\n",
      "Epoch: 4/15, Step: 11009/16463, Loss: 0.001565, Avg Loss: 0.130\n",
      "Epoch: 4/15, Step: 11110/16463, Loss: 0.002436, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 11211/16463, Loss: 0.027274, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 11312/16463, Loss: 0.001605, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 11413/16463, Loss: 0.004094, Avg Loss: 0.130\n",
      "Epoch: 4/15, Step: 11514/16463, Loss: 0.081280, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 11615/16463, Loss: 0.008117, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 11716/16463, Loss: 0.035407, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 11817/16463, Loss: 0.122293, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 11918/16463, Loss: 0.001384, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12019/16463, Loss: 1.061966, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12120/16463, Loss: 0.003168, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12221/16463, Loss: 0.295318, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12322/16463, Loss: 0.118473, Avg Loss: 0.129\n",
      "Epoch: 4/15, Step: 12423/16463, Loss: 0.016075, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12524/16463, Loss: 0.006577, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12625/16463, Loss: 0.001985, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12726/16463, Loss: 0.128342, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12827/16463, Loss: 0.001074, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 12928/16463, Loss: 0.000717, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13029/16463, Loss: 0.004301, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13130/16463, Loss: 0.268003, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13231/16463, Loss: 0.024848, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13332/16463, Loss: 0.012818, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13433/16463, Loss: 0.004117, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13534/16463, Loss: 0.001933, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13635/16463, Loss: 0.013076, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 13736/16463, Loss: 0.004734, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13837/16463, Loss: 0.030178, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 13938/16463, Loss: 0.295379, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 14039/16463, Loss: 0.002859, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 14140/16463, Loss: 0.019423, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 14241/16463, Loss: 0.001957, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 14342/16463, Loss: 0.015548, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 14443/16463, Loss: 0.001489, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 14544/16463, Loss: 0.026367, Avg Loss: 0.128\n",
      "Epoch: 4/15, Step: 14645/16463, Loss: 0.009663, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 14746/16463, Loss: 0.001315, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 14847/16463, Loss: 0.007043, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 14948/16463, Loss: 0.810263, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 15049/16463, Loss: 0.032401, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 15150/16463, Loss: 0.019352, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 15251/16463, Loss: 0.031220, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 15352/16463, Loss: 0.019572, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 15453/16463, Loss: 0.001897, Avg Loss: 0.127\n",
      "Epoch: 4/15, Step: 15554/16463, Loss: 0.002022, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 15655/16463, Loss: 0.001847, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 15756/16463, Loss: 0.022763, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 15857/16463, Loss: 0.000841, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 15958/16463, Loss: 0.001412, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 16059/16463, Loss: 0.002316, Avg Loss: 0.125\n",
      "Epoch: 4/15, Step: 16160/16463, Loss: 0.000860, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 16261/16463, Loss: 0.004168, Avg Loss: 0.126\n",
      "Epoch: 4/15, Step: 16362/16463, Loss: 1.642770, Avg Loss: 0.125\n",
      "Epoch 4/15, Training Loss: 0.1252\n",
      "Validation Accuracy: 0.9226\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "Epoch: 5/15, Step: 0/16463, Loss: 0.000625, Avg Loss: 0.001\n",
      "Epoch: 5/15, Step: 101/16463, Loss: 0.001527, Avg Loss: 0.027\n",
      "Epoch: 5/15, Step: 202/16463, Loss: 0.005085, Avg Loss: 0.079\n",
      "Epoch: 5/15, Step: 303/16463, Loss: 1.787613, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 404/16463, Loss: 0.019203, Avg Loss: 0.080\n",
      "Epoch: 5/15, Step: 505/16463, Loss: 0.006692, Avg Loss: 0.071\n",
      "Epoch: 5/15, Step: 606/16463, Loss: 0.000829, Avg Loss: 0.074\n",
      "Epoch: 5/15, Step: 707/16463, Loss: 0.002584, Avg Loss: 0.073\n",
      "Epoch: 5/15, Step: 808/16463, Loss: 0.001840, Avg Loss: 0.081\n",
      "Epoch: 5/15, Step: 909/16463, Loss: 0.003564, Avg Loss: 0.082\n",
      "Epoch: 5/15, Step: 1010/16463, Loss: 0.423191, Avg Loss: 0.086\n",
      "Epoch: 5/15, Step: 1111/16463, Loss: 0.003773, Avg Loss: 0.083\n",
      "Epoch: 5/15, Step: 1212/16463, Loss: 0.056343, Avg Loss: 0.084\n",
      "Epoch: 5/15, Step: 1313/16463, Loss: 0.001919, Avg Loss: 0.084\n",
      "Epoch: 5/15, Step: 1414/16463, Loss: 0.000618, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 1515/16463, Loss: 0.001870, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 1616/16463, Loss: 0.018837, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 1717/16463, Loss: 0.001174, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 1818/16463, Loss: 0.020168, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 1919/16463, Loss: 0.003813, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 2020/16463, Loss: 0.003638, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 2121/16463, Loss: 0.016528, Avg Loss: 0.094\n",
      "Epoch: 5/15, Step: 2222/16463, Loss: 0.003230, Avg Loss: 0.094\n",
      "Epoch: 5/15, Step: 2323/16463, Loss: 0.009139, Avg Loss: 0.094\n",
      "Epoch: 5/15, Step: 2424/16463, Loss: 0.003066, Avg Loss: 0.094\n",
      "Epoch: 5/15, Step: 2525/16463, Loss: 0.002272, Avg Loss: 0.096\n",
      "Epoch: 5/15, Step: 2626/16463, Loss: 0.001558, Avg Loss: 0.096\n",
      "Epoch: 5/15, Step: 2727/16463, Loss: 0.000838, Avg Loss: 0.095\n",
      "Epoch: 5/15, Step: 2828/16463, Loss: 0.001203, Avg Loss: 0.095\n",
      "Epoch: 5/15, Step: 2929/16463, Loss: 0.001000, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 3030/16463, Loss: 0.668178, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 3131/16463, Loss: 0.000687, Avg Loss: 0.094\n",
      "Epoch: 5/15, Step: 3232/16463, Loss: 0.004831, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 3333/16463, Loss: 0.269314, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 3434/16463, Loss: 0.030811, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 3535/16463, Loss: 0.173554, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 3636/16463, Loss: 0.001136, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 3737/16463, Loss: 0.009920, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 3838/16463, Loss: 0.024308, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 3939/16463, Loss: 0.001137, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 4040/16463, Loss: 0.001702, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 4141/16463, Loss: 0.002453, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 4242/16463, Loss: 0.000640, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 4343/16463, Loss: 0.014353, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 4444/16463, Loss: 0.023826, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 4545/16463, Loss: 0.002334, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 4646/16463, Loss: 0.000946, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 4747/16463, Loss: 0.002489, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 4848/16463, Loss: 0.007361, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 4949/16463, Loss: 0.003845, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 5050/16463, Loss: 0.257171, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 5151/16463, Loss: 1.961367, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 5252/16463, Loss: 0.001324, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 5353/16463, Loss: 0.001398, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 5454/16463, Loss: 0.047727, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 5555/16463, Loss: 0.001606, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 5656/16463, Loss: 0.002802, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 5757/16463, Loss: 0.001337, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 5858/16463, Loss: 0.008865, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 5959/16463, Loss: 0.011328, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 6060/16463, Loss: 0.000572, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 6161/16463, Loss: 0.013075, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 6262/16463, Loss: 0.000818, Avg Loss: 0.087\n",
      "Epoch: 5/15, Step: 6363/16463, Loss: 0.311652, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 6464/16463, Loss: 0.039475, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 6565/16463, Loss: 0.003264, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 6666/16463, Loss: 0.000937, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 6767/16463, Loss: 0.001583, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 6868/16463, Loss: 0.023953, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 6969/16463, Loss: 0.004245, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 7070/16463, Loss: 0.001497, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 7171/16463, Loss: 0.010354, Avg Loss: 0.088\n",
      "Epoch: 5/15, Step: 7272/16463, Loss: 0.000933, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 7373/16463, Loss: 0.001302, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 7474/16463, Loss: 0.001200, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 7575/16463, Loss: 0.007070, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 7676/16463, Loss: 0.000637, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 7777/16463, Loss: 0.001979, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 7878/16463, Loss: 0.000893, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 7979/16463, Loss: 0.000928, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 8080/16463, Loss: 0.009562, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8181/16463, Loss: 0.001428, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8282/16463, Loss: 0.159684, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8383/16463, Loss: 0.016790, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8484/16463, Loss: 0.000946, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8585/16463, Loss: 0.383046, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8686/16463, Loss: 0.037489, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8787/16463, Loss: 0.001387, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 8888/16463, Loss: 0.302034, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 8989/16463, Loss: 2.097353, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 9090/16463, Loss: 0.000914, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 9191/16463, Loss: 0.005190, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 9292/16463, Loss: 0.675627, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 9393/16463, Loss: 0.001251, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 9494/16463, Loss: 0.084221, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 9595/16463, Loss: 0.001361, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 9696/16463, Loss: 0.010203, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 9797/16463, Loss: 0.000817, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 9898/16463, Loss: 1.432622, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 9999/16463, Loss: 0.004819, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 10100/16463, Loss: 0.004608, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 10201/16463, Loss: 0.000867, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 10302/16463, Loss: 0.842434, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 10403/16463, Loss: 0.236932, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 10504/16463, Loss: 0.001542, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 10605/16463, Loss: 0.001009, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 10706/16463, Loss: 0.001225, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 10807/16463, Loss: 0.001738, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 10908/16463, Loss: 0.238224, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11009/16463, Loss: 0.178190, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11110/16463, Loss: 0.000910, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11211/16463, Loss: 0.000857, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11312/16463, Loss: 0.060938, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11413/16463, Loss: 0.002050, Avg Loss: 0.089\n",
      "Epoch: 5/15, Step: 11514/16463, Loss: 0.001074, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11615/16463, Loss: 0.083205, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11716/16463, Loss: 0.002218, Avg Loss: 0.090\n",
      "Epoch: 5/15, Step: 11817/16463, Loss: 0.001779, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 11918/16463, Loss: 0.003171, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 12019/16463, Loss: 0.003202, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 12120/16463, Loss: 0.005333, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 12221/16463, Loss: 0.029740, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 12322/16463, Loss: 0.007117, Avg Loss: 0.091\n",
      "Epoch: 5/15, Step: 12423/16463, Loss: 0.000742, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 12524/16463, Loss: 0.007937, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 12625/16463, Loss: 0.001298, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 12726/16463, Loss: 0.000781, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 12827/16463, Loss: 0.030876, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 12928/16463, Loss: 0.010602, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13029/16463, Loss: 0.004881, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13130/16463, Loss: 0.001706, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13231/16463, Loss: 0.001702, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13332/16463, Loss: 0.002603, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13433/16463, Loss: 0.102585, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13534/16463, Loss: 0.005696, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13635/16463, Loss: 0.001249, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13736/16463, Loss: 0.002746, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13837/16463, Loss: 0.007827, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 13938/16463, Loss: 0.010518, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14039/16463, Loss: 0.005820, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14140/16463, Loss: 0.020070, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14241/16463, Loss: 0.000535, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14342/16463, Loss: 0.012732, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14443/16463, Loss: 0.000831, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14544/16463, Loss: 2.818632, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14645/16463, Loss: 0.074520, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14746/16463, Loss: 0.001706, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14847/16463, Loss: 0.000622, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 14948/16463, Loss: 0.000440, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15049/16463, Loss: 0.001327, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15150/16463, Loss: 0.150424, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 15251/16463, Loss: 0.001969, Avg Loss: 0.092\n",
      "Epoch: 5/15, Step: 15352/16463, Loss: 0.033766, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15453/16463, Loss: 0.207307, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15554/16463, Loss: 0.002734, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15655/16463, Loss: 0.001725, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15756/16463, Loss: 0.001276, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15857/16463, Loss: 0.012011, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 15958/16463, Loss: 0.036957, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 16059/16463, Loss: 0.919451, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 16160/16463, Loss: 0.014399, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 16261/16463, Loss: 0.002207, Avg Loss: 0.093\n",
      "Epoch: 5/15, Step: 16362/16463, Loss: 0.002131, Avg Loss: 0.094\n",
      "Epoch 5/15, Training Loss: 0.0939\n",
      "Validation Accuracy: 0.9276\n",
      "New best model found with accuracy: 0.9276. Saving model...\n",
      "Model saved.\n",
      "Epoch: 6/15, Step: 0/16463, Loss: 0.001129, Avg Loss: 0.001\n",
      "Epoch: 6/15, Step: 101/16463, Loss: 0.002068, Avg Loss: 0.119\n",
      "Epoch: 6/15, Step: 202/16463, Loss: 0.007920, Avg Loss: 0.092\n",
      "Epoch: 6/15, Step: 303/16463, Loss: 0.001402, Avg Loss: 0.091\n",
      "Epoch: 6/15, Step: 404/16463, Loss: 0.004101, Avg Loss: 0.087\n",
      "Epoch: 6/15, Step: 505/16463, Loss: 0.016413, Avg Loss: 0.086\n",
      "Epoch: 6/15, Step: 606/16463, Loss: 0.008063, Avg Loss: 0.086\n",
      "Epoch: 6/15, Step: 707/16463, Loss: 0.002877, Avg Loss: 0.078\n",
      "Epoch: 6/15, Step: 808/16463, Loss: 0.001901, Avg Loss: 0.085\n",
      "Epoch: 6/15, Step: 909/16463, Loss: 0.001745, Avg Loss: 0.085\n",
      "Epoch: 6/15, Step: 1010/16463, Loss: 0.004284, Avg Loss: 0.080\n",
      "Epoch: 6/15, Step: 1111/16463, Loss: 0.006732, Avg Loss: 0.077\n",
      "Epoch: 6/15, Step: 1212/16463, Loss: 0.131759, Avg Loss: 0.081\n",
      "Epoch: 6/15, Step: 1313/16463, Loss: 0.001338, Avg Loss: 0.080\n",
      "Epoch: 6/15, Step: 1414/16463, Loss: 0.000489, Avg Loss: 0.080\n",
      "Epoch: 6/15, Step: 1515/16463, Loss: 0.000871, Avg Loss: 0.082\n",
      "Epoch: 6/15, Step: 1616/16463, Loss: 0.017578, Avg Loss: 0.081\n",
      "Epoch: 6/15, Step: 1717/16463, Loss: 0.000934, Avg Loss: 0.080\n",
      "Epoch: 6/15, Step: 1818/16463, Loss: 0.001321, Avg Loss: 0.080\n",
      "Epoch: 6/15, Step: 1919/16463, Loss: 0.001061, Avg Loss: 0.081\n",
      "Epoch: 6/15, Step: 2020/16463, Loss: 0.000724, Avg Loss: 0.079\n",
      "Epoch: 6/15, Step: 2121/16463, Loss: 0.535566, Avg Loss: 0.079\n",
      "Epoch: 6/15, Step: 2222/16463, Loss: 0.000920, Avg Loss: 0.078\n",
      "Epoch: 6/15, Step: 2323/16463, Loss: 0.017999, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 2424/16463, Loss: 0.004251, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 2525/16463, Loss: 0.002582, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 2626/16463, Loss: 0.000942, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 2727/16463, Loss: 0.000966, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 2828/16463, Loss: 0.001119, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 2929/16463, Loss: 0.001205, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 3030/16463, Loss: 0.000441, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 3131/16463, Loss: 0.041539, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 3232/16463, Loss: 0.002533, Avg Loss: 0.070\n",
      "Epoch: 6/15, Step: 3333/16463, Loss: 0.010385, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 3434/16463, Loss: 0.003862, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 3535/16463, Loss: 0.025341, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 3636/16463, Loss: 0.000350, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 3737/16463, Loss: 0.000972, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 3838/16463, Loss: 0.000717, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 3939/16463, Loss: 0.000408, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 4040/16463, Loss: 0.001392, Avg Loss: 0.070\n",
      "Epoch: 6/15, Step: 4141/16463, Loss: 0.003127, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 4242/16463, Loss: 0.001468, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 4343/16463, Loss: 0.002076, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 4444/16463, Loss: 0.000825, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 4545/16463, Loss: 0.024039, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 4646/16463, Loss: 0.006298, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 4747/16463, Loss: 0.002304, Avg Loss: 0.068\n",
      "Epoch: 6/15, Step: 4848/16463, Loss: 0.002003, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 4949/16463, Loss: 0.006286, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 5050/16463, Loss: 0.001214, Avg Loss: 0.069\n",
      "Epoch: 6/15, Step: 5151/16463, Loss: 0.000618, Avg Loss: 0.070\n",
      "Epoch: 6/15, Step: 5252/16463, Loss: 0.001900, Avg Loss: 0.070\n",
      "Epoch: 6/15, Step: 5353/16463, Loss: 0.137423, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 5454/16463, Loss: 0.002060, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 5555/16463, Loss: 0.001258, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 5656/16463, Loss: 0.300733, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 5757/16463, Loss: 0.004215, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 5858/16463, Loss: 0.000893, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 5959/16463, Loss: 0.002007, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 6060/16463, Loss: 0.001610, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 6161/16463, Loss: 0.000422, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 6262/16463, Loss: 0.004554, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 6363/16463, Loss: 0.033506, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 6464/16463, Loss: 0.001822, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 6565/16463, Loss: 0.567025, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 6666/16463, Loss: 0.001770, Avg Loss: 0.071\n",
      "Epoch: 6/15, Step: 6767/16463, Loss: 0.006694, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 6868/16463, Loss: 0.014170, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 6969/16463, Loss: 0.000675, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 7070/16463, Loss: 0.000629, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 7171/16463, Loss: 0.000931, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 7272/16463, Loss: 0.000415, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 7373/16463, Loss: 0.006929, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 7474/16463, Loss: 0.005644, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 7575/16463, Loss: 0.003046, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 7676/16463, Loss: 0.013426, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 7777/16463, Loss: 0.002718, Avg Loss: 0.072\n",
      "Epoch: 6/15, Step: 7878/16463, Loss: 0.007027, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 7979/16463, Loss: 0.002951, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 8080/16463, Loss: 0.000862, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 8181/16463, Loss: 0.035607, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 8282/16463, Loss: 0.001356, Avg Loss: 0.073\n",
      "Epoch: 6/15, Step: 8383/16463, Loss: 0.001684, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 8484/16463, Loss: 0.022835, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 8585/16463, Loss: 0.000933, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 8686/16463, Loss: 0.576487, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 8787/16463, Loss: 0.001306, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 8888/16463, Loss: 1.708950, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 8989/16463, Loss: 0.008842, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 9090/16463, Loss: 0.001185, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 9191/16463, Loss: 0.005005, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 9292/16463, Loss: 0.001398, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 9393/16463, Loss: 0.001928, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 9494/16463, Loss: 0.005956, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 9595/16463, Loss: 0.000741, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 9696/16463, Loss: 0.295416, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 9797/16463, Loss: 0.004225, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 9898/16463, Loss: 0.000510, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 9999/16463, Loss: 0.001029, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 10100/16463, Loss: 0.005012, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 10201/16463, Loss: 0.007908, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 10302/16463, Loss: 0.000593, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 10403/16463, Loss: 0.008805, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 10504/16463, Loss: 0.004072, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 10605/16463, Loss: 0.000758, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 10706/16463, Loss: 0.000481, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 10807/16463, Loss: 0.074825, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 10908/16463, Loss: 0.001446, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 11009/16463, Loss: 0.749943, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 11110/16463, Loss: 0.017375, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11211/16463, Loss: 0.001859, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11312/16463, Loss: 0.000580, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11413/16463, Loss: 0.000965, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11514/16463, Loss: 0.001079, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11615/16463, Loss: 0.019191, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11716/16463, Loss: 0.001594, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11817/16463, Loss: 0.009235, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 11918/16463, Loss: 0.001016, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 12019/16463, Loss: 0.002412, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 12120/16463, Loss: 0.003439, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 12221/16463, Loss: 0.000753, Avg Loss: 0.074\n",
      "Epoch: 6/15, Step: 12322/16463, Loss: 0.003918, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 12423/16463, Loss: 0.004328, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 12524/16463, Loss: 0.002391, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 12625/16463, Loss: 0.015218, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 12726/16463, Loss: 0.001645, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 12827/16463, Loss: 0.128009, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 12928/16463, Loss: 0.001603, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 13029/16463, Loss: 0.000944, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 13130/16463, Loss: 0.013666, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 13231/16463, Loss: 0.000621, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 13332/16463, Loss: 0.046921, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 13433/16463, Loss: 0.000487, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 13534/16463, Loss: 0.060366, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 13635/16463, Loss: 0.000751, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 13736/16463, Loss: 0.000975, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 13837/16463, Loss: 0.014036, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 13938/16463, Loss: 0.002336, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 14039/16463, Loss: 0.000853, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 14140/16463, Loss: 0.000393, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 14241/16463, Loss: 0.000873, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 14342/16463, Loss: 0.001566, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 14443/16463, Loss: 0.001128, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 14544/16463, Loss: 0.002111, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 14645/16463, Loss: 0.001324, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 14746/16463, Loss: 0.000815, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 14847/16463, Loss: 0.001643, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 14948/16463, Loss: 0.460608, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 15049/16463, Loss: 0.100159, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 15150/16463, Loss: 0.000998, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 15251/16463, Loss: 0.001690, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 15352/16463, Loss: 0.000541, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 15453/16463, Loss: 0.000991, Avg Loss: 0.076\n",
      "Epoch: 6/15, Step: 15554/16463, Loss: 0.001794, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 15655/16463, Loss: 0.000452, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 15756/16463, Loss: 0.021516, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 15857/16463, Loss: 0.000774, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 15958/16463, Loss: 0.004227, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 16059/16463, Loss: 0.015207, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 16160/16463, Loss: 0.001493, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 16261/16463, Loss: 0.008832, Avg Loss: 0.075\n",
      "Epoch: 6/15, Step: 16362/16463, Loss: 0.987968, Avg Loss: 0.075\n",
      "Epoch 6/15, Training Loss: 0.0750\n",
      "Validation Accuracy: 0.9271\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "Epoch: 7/15, Step: 0/16463, Loss: 0.000577, Avg Loss: 0.001\n",
      "Epoch: 7/15, Step: 101/16463, Loss: 0.000763, Avg Loss: 0.023\n",
      "Epoch: 7/15, Step: 202/16463, Loss: 0.000480, Avg Loss: 0.021\n",
      "Epoch: 7/15, Step: 303/16463, Loss: 0.001028, Avg Loss: 0.040\n",
      "Epoch: 7/15, Step: 404/16463, Loss: 0.000701, Avg Loss: 0.035\n",
      "Epoch: 7/15, Step: 505/16463, Loss: 2.247196, Avg Loss: 0.045\n",
      "Epoch: 7/15, Step: 606/16463, Loss: 0.014350, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 707/16463, Loss: 0.001046, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 808/16463, Loss: 0.000834, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 909/16463, Loss: 0.002311, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 1010/16463, Loss: 0.023313, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 1111/16463, Loss: 0.001312, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 1212/16463, Loss: 0.003092, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 1313/16463, Loss: 0.003789, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 1414/16463, Loss: 0.000527, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 1515/16463, Loss: 0.013714, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 1616/16463, Loss: 0.001464, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 1717/16463, Loss: 0.004910, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 1818/16463, Loss: 0.018694, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 1919/16463, Loss: 0.009041, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 2020/16463, Loss: 0.016098, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 2121/16463, Loss: 0.001396, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 2222/16463, Loss: 0.000507, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 2323/16463, Loss: 0.000336, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 2424/16463, Loss: 0.001188, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 2525/16463, Loss: 0.000457, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 2626/16463, Loss: 0.002505, Avg Loss: 0.049\n",
      "Epoch: 7/15, Step: 2727/16463, Loss: 0.000283, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 2828/16463, Loss: 0.003311, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 2929/16463, Loss: 0.000327, Avg Loss: 0.047\n",
      "Epoch: 7/15, Step: 3030/16463, Loss: 0.000894, Avg Loss: 0.047\n",
      "Epoch: 7/15, Step: 3131/16463, Loss: 0.001572, Avg Loss: 0.049\n",
      "Epoch: 7/15, Step: 3232/16463, Loss: 0.000284, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 3333/16463, Loss: 0.000730, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 3434/16463, Loss: 0.005089, Avg Loss: 0.049\n",
      "Epoch: 7/15, Step: 3535/16463, Loss: 0.034117, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 3636/16463, Loss: 0.000287, Avg Loss: 0.049\n",
      "Epoch: 7/15, Step: 3737/16463, Loss: 0.004104, Avg Loss: 0.049\n",
      "Epoch: 7/15, Step: 3838/16463, Loss: 0.000410, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 3939/16463, Loss: 0.000262, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 4040/16463, Loss: 0.008678, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 4141/16463, Loss: 0.000755, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 4242/16463, Loss: 0.000313, Avg Loss: 0.048\n",
      "Epoch: 7/15, Step: 4343/16463, Loss: 0.002213, Avg Loss: 0.049\n",
      "Epoch: 7/15, Step: 4444/16463, Loss: 0.000457, Avg Loss: 0.049\n",
      "Epoch: 7/15, Step: 4545/16463, Loss: 0.000402, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 4646/16463, Loss: 0.000549, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 4747/16463, Loss: 0.000385, Avg Loss: 0.050\n",
      "Epoch: 7/15, Step: 4848/16463, Loss: 0.011021, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 4949/16463, Loss: 0.002390, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 5050/16463, Loss: 0.034896, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 5151/16463, Loss: 0.002812, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 5252/16463, Loss: 0.014819, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 5353/16463, Loss: 0.000738, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 5454/16463, Loss: 0.000781, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 5555/16463, Loss: 0.000612, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 5656/16463, Loss: 0.000471, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 5757/16463, Loss: 0.002672, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 5858/16463, Loss: 0.000602, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 5959/16463, Loss: 0.000839, Avg Loss: 0.051\n",
      "Epoch: 7/15, Step: 6060/16463, Loss: 0.003719, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 6161/16463, Loss: 0.000647, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 6262/16463, Loss: 0.003278, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 6363/16463, Loss: 0.000323, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 6464/16463, Loss: 0.085581, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 6565/16463, Loss: 0.000506, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 6666/16463, Loss: 0.002473, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 6767/16463, Loss: 0.003379, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 6868/16463, Loss: 0.000503, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 6969/16463, Loss: 0.000392, Avg Loss: 0.052\n",
      "Epoch: 7/15, Step: 7070/16463, Loss: 0.015903, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 7171/16463, Loss: 0.011584, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 7272/16463, Loss: 0.000836, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 7373/16463, Loss: 0.000348, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 7474/16463, Loss: 0.000297, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 7575/16463, Loss: 0.000812, Avg Loss: 0.053\n",
      "Epoch: 7/15, Step: 7676/16463, Loss: 0.003852, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 7777/16463, Loss: 0.001448, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 7878/16463, Loss: 0.016652, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 7979/16463, Loss: 0.004427, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 8080/16463, Loss: 0.001180, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8181/16463, Loss: 0.001727, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8282/16463, Loss: 0.000888, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8383/16463, Loss: 0.000805, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8484/16463, Loss: 0.000517, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8585/16463, Loss: 0.000229, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8686/16463, Loss: 0.000707, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8787/16463, Loss: 0.000452, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 8888/16463, Loss: 0.000530, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 8989/16463, Loss: 0.029782, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 9090/16463, Loss: 0.017356, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 9191/16463, Loss: 0.002633, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9292/16463, Loss: 0.000602, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9393/16463, Loss: 0.000856, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9494/16463, Loss: 0.002564, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9595/16463, Loss: 0.000481, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9696/16463, Loss: 0.000845, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9797/16463, Loss: 0.001010, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9898/16463, Loss: 0.000376, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 9999/16463, Loss: 0.009277, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10100/16463, Loss: 0.000735, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10201/16463, Loss: 0.000679, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10302/16463, Loss: 0.012395, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10403/16463, Loss: 0.000782, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10504/16463, Loss: 0.000382, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10605/16463, Loss: 0.000248, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10706/16463, Loss: 0.177611, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 10807/16463, Loss: 0.000420, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 10908/16463, Loss: 0.000675, Avg Loss: 0.054\n",
      "Epoch: 7/15, Step: 11009/16463, Loss: 0.000288, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11110/16463, Loss: 0.000793, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11211/16463, Loss: 0.000630, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11312/16463, Loss: 0.000360, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11413/16463, Loss: 0.000818, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11514/16463, Loss: 0.000431, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11615/16463, Loss: 0.001161, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11716/16463, Loss: 0.015906, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11817/16463, Loss: 0.000419, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 11918/16463, Loss: 0.000453, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12019/16463, Loss: 0.001024, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12120/16463, Loss: 0.006757, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12221/16463, Loss: 0.002056, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12322/16463, Loss: 0.001033, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12423/16463, Loss: 0.000568, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12524/16463, Loss: 1.775082, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12625/16463, Loss: 0.000501, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12726/16463, Loss: 0.001556, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12827/16463, Loss: 0.945129, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 12928/16463, Loss: 0.001197, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 13029/16463, Loss: 0.003496, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 13130/16463, Loss: 0.000890, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 13231/16463, Loss: 0.000886, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 13332/16463, Loss: 0.000282, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 13433/16463, Loss: 0.181629, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 13534/16463, Loss: 0.000713, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 13635/16463, Loss: 0.045109, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 13736/16463, Loss: 0.000471, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 13837/16463, Loss: 0.001738, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 13938/16463, Loss: 0.000791, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 14039/16463, Loss: 0.000935, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 14140/16463, Loss: 0.029924, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 14241/16463, Loss: 0.000907, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 14342/16463, Loss: 0.001532, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 14443/16463, Loss: 0.000539, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 14544/16463, Loss: 0.001394, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 14645/16463, Loss: 0.000493, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 14746/16463, Loss: 0.006338, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 14847/16463, Loss: 0.000431, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 14948/16463, Loss: 0.002498, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15049/16463, Loss: 0.277714, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15150/16463, Loss: 0.044543, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15251/16463, Loss: 0.020334, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15352/16463, Loss: 0.445067, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15453/16463, Loss: 0.000786, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 15554/16463, Loss: 0.019006, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15655/16463, Loss: 0.245284, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15756/16463, Loss: 0.000390, Avg Loss: 0.055\n",
      "Epoch: 7/15, Step: 15857/16463, Loss: 0.000607, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 15958/16463, Loss: 0.000263, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 16059/16463, Loss: 0.005089, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 16160/16463, Loss: 0.000521, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 16261/16463, Loss: 0.974270, Avg Loss: 0.056\n",
      "Epoch: 7/15, Step: 16362/16463, Loss: 0.000506, Avg Loss: 0.056\n",
      "Epoch 7/15, Training Loss: 0.0555\n",
      "Validation Accuracy: 0.9276\n",
      "No improvement in validation accuracy for 2 epochs.\n",
      "Epoch: 8/15, Step: 0/16463, Loss: 0.000415, Avg Loss: 0.000\n",
      "Epoch: 8/15, Step: 101/16463, Loss: 0.000391, Avg Loss: 0.013\n",
      "Epoch: 8/15, Step: 202/16463, Loss: 0.154327, Avg Loss: 0.024\n",
      "Epoch: 8/15, Step: 303/16463, Loss: 0.009719, Avg Loss: 0.049\n",
      "Epoch: 8/15, Step: 404/16463, Loss: 0.000452, Avg Loss: 0.042\n",
      "Epoch: 8/15, Step: 505/16463, Loss: 0.000555, Avg Loss: 0.040\n",
      "Epoch: 8/15, Step: 606/16463, Loss: 0.000548, Avg Loss: 0.036\n",
      "Epoch: 8/15, Step: 707/16463, Loss: 0.005160, Avg Loss: 0.036\n",
      "Epoch: 8/15, Step: 808/16463, Loss: 3.780247, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 909/16463, Loss: 0.000508, Avg Loss: 0.040\n",
      "Epoch: 8/15, Step: 1010/16463, Loss: 0.003336, Avg Loss: 0.043\n",
      "Epoch: 8/15, Step: 1111/16463, Loss: 0.001021, Avg Loss: 0.042\n",
      "Epoch: 8/15, Step: 1212/16463, Loss: 0.000498, Avg Loss: 0.040\n",
      "Epoch: 8/15, Step: 1313/16463, Loss: 0.000575, Avg Loss: 0.041\n",
      "Epoch: 8/15, Step: 1414/16463, Loss: 0.000388, Avg Loss: 0.042\n",
      "Epoch: 8/15, Step: 1515/16463, Loss: 0.000291, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 1616/16463, Loss: 0.002554, Avg Loss: 0.043\n",
      "Epoch: 8/15, Step: 1717/16463, Loss: 0.000335, Avg Loss: 0.041\n",
      "Epoch: 8/15, Step: 1818/16463, Loss: 0.000470, Avg Loss: 0.040\n",
      "Epoch: 8/15, Step: 1919/16463, Loss: 0.000393, Avg Loss: 0.042\n",
      "Epoch: 8/15, Step: 2020/16463, Loss: 0.000987, Avg Loss: 0.043\n",
      "Epoch: 8/15, Step: 2121/16463, Loss: 0.008699, Avg Loss: 0.043\n",
      "Epoch: 8/15, Step: 2222/16463, Loss: 0.000344, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 2323/16463, Loss: 0.046236, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 2424/16463, Loss: 0.000460, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 2525/16463, Loss: 0.002021, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 2626/16463, Loss: 0.000577, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 2727/16463, Loss: 0.046220, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 2828/16463, Loss: 0.000405, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 2929/16463, Loss: 0.007801, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 3030/16463, Loss: 0.000860, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 3131/16463, Loss: 0.000698, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 3232/16463, Loss: 0.000306, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 3333/16463, Loss: 0.000544, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 3434/16463, Loss: 0.001096, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 3535/16463, Loss: 0.000258, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 3636/16463, Loss: 0.000378, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 3737/16463, Loss: 0.001719, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 3838/16463, Loss: 0.000268, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 3939/16463, Loss: 0.000832, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 4040/16463, Loss: 0.000958, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 4141/16463, Loss: 1.584098, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 4242/16463, Loss: 0.000356, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 4343/16463, Loss: 0.001007, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 4444/16463, Loss: 0.001907, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 4545/16463, Loss: 1.378720, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 4646/16463, Loss: 0.000865, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 4747/16463, Loss: 0.000549, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 4848/16463, Loss: 0.001288, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 4949/16463, Loss: 0.000297, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 5050/16463, Loss: 0.000310, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5151/16463, Loss: 0.000478, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5252/16463, Loss: 0.002388, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5353/16463, Loss: 0.000475, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5454/16463, Loss: 0.000275, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5555/16463, Loss: 0.000368, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5656/16463, Loss: 0.000370, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5757/16463, Loss: 0.000375, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5858/16463, Loss: 0.000768, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 5959/16463, Loss: 0.004891, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 6060/16463, Loss: 0.000466, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 6161/16463, Loss: 0.000488, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 6262/16463, Loss: 0.001645, Avg Loss: 0.043\n",
      "Epoch: 8/15, Step: 6363/16463, Loss: 0.000290, Avg Loss: 0.043\n",
      "Epoch: 8/15, Step: 6464/16463, Loss: 0.003042, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 6565/16463, Loss: 0.000427, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 6666/16463, Loss: 0.032238, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 6767/16463, Loss: 0.000440, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 6868/16463, Loss: 0.001207, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 6969/16463, Loss: 0.000385, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7070/16463, Loss: 0.001367, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7171/16463, Loss: 0.004453, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7272/16463, Loss: 0.011653, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7373/16463, Loss: 0.000492, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7474/16463, Loss: 0.661905, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7575/16463, Loss: 0.025329, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7676/16463, Loss: 0.592238, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7777/16463, Loss: 0.000485, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7878/16463, Loss: 0.000227, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 7979/16463, Loss: 0.000460, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8080/16463, Loss: 0.000243, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8181/16463, Loss: 0.004004, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8282/16463, Loss: 0.007604, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8383/16463, Loss: 0.000351, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8484/16463, Loss: 0.000289, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8585/16463, Loss: 0.000318, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8686/16463, Loss: 0.000579, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 8787/16463, Loss: 0.010455, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 8888/16463, Loss: 0.001403, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 8989/16463, Loss: 0.000491, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9090/16463, Loss: 0.251022, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9191/16463, Loss: 0.114213, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9292/16463, Loss: 0.000673, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9393/16463, Loss: 0.862964, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9494/16463, Loss: 0.006074, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9595/16463, Loss: 0.054597, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9696/16463, Loss: 0.004314, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9797/16463, Loss: 0.094229, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9898/16463, Loss: 0.000387, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 9999/16463, Loss: 0.007778, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10100/16463, Loss: 0.001147, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10201/16463, Loss: 0.000424, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10302/16463, Loss: 0.035511, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10403/16463, Loss: 0.001196, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10504/16463, Loss: 0.000472, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10605/16463, Loss: 0.000221, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10706/16463, Loss: 0.042850, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 10807/16463, Loss: 0.008097, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 10908/16463, Loss: 0.139445, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11009/16463, Loss: 0.304757, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11110/16463, Loss: 0.001048, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11211/16463, Loss: 0.000484, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11312/16463, Loss: 0.000339, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11413/16463, Loss: 0.207597, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11514/16463, Loss: 0.001086, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11615/16463, Loss: 0.000604, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 11716/16463, Loss: 0.000323, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 11817/16463, Loss: 0.000725, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 11918/16463, Loss: 0.000493, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12019/16463, Loss: 0.001319, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12120/16463, Loss: 0.003716, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12221/16463, Loss: 0.001220, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12322/16463, Loss: 0.003264, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12423/16463, Loss: 0.001879, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12524/16463, Loss: 0.000391, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12625/16463, Loss: 0.000318, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 12726/16463, Loss: 0.000313, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 12827/16463, Loss: 0.001234, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 12928/16463, Loss: 0.004775, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13029/16463, Loss: 0.000344, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13130/16463, Loss: 0.000445, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 13231/16463, Loss: 0.000425, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13332/16463, Loss: 0.003968, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13433/16463, Loss: 0.000355, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13534/16463, Loss: 0.000752, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13635/16463, Loss: 0.000676, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13736/16463, Loss: 0.000340, Avg Loss: 0.046\n",
      "Epoch: 8/15, Step: 13837/16463, Loss: 0.005926, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 13938/16463, Loss: 0.002116, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14039/16463, Loss: 0.003795, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14140/16463, Loss: 0.000648, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14241/16463, Loss: 0.000356, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14342/16463, Loss: 0.238762, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14443/16463, Loss: 0.017622, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14544/16463, Loss: 0.000377, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14645/16463, Loss: 1.277146, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14746/16463, Loss: 0.000731, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14847/16463, Loss: 0.158426, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 14948/16463, Loss: 0.000319, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 15049/16463, Loss: 0.000419, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15150/16463, Loss: 0.019394, Avg Loss: 0.045\n",
      "Epoch: 8/15, Step: 15251/16463, Loss: 0.001123, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15352/16463, Loss: 0.000453, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15453/16463, Loss: 0.001374, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15554/16463, Loss: 0.028043, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15655/16463, Loss: 0.000401, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15756/16463, Loss: 0.000706, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15857/16463, Loss: 0.002539, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 15958/16463, Loss: 0.002971, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 16059/16463, Loss: 0.000270, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 16160/16463, Loss: 0.713709, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 16261/16463, Loss: 0.004405, Avg Loss: 0.044\n",
      "Epoch: 8/15, Step: 16362/16463, Loss: 0.025257, Avg Loss: 0.044\n",
      "Epoch 8/15, Training Loss: 0.0439\n",
      "Validation Accuracy: 0.9196\n",
      "No improvement in validation accuracy for 3 epochs.\n",
      "Early stopping triggered.\n",
      "Training completed. Best validation accuracy: 0.9276.\n"
     ]
    }
   ],
   "source": [
    "train_input_ex = [InputExample(texts=[tc], label=l) for tc, l in zip(df_train[\"OriginalTweet\"], df_train[\"label\"])]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts = [x.texts[0] for x in batch]\n",
    "    labels = torch.tensor([x.label for x in batch])\n",
    "    return texts, labels\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(train_input_ex) * train_ratio)\n",
    "val_size = len(train_input_ex) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_input_ex, [train_size, val_size])\n",
    "\n",
    "batch_size = 2\n",
    "train_dataLoader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
    "val_dataLoader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "# Para el entrenamiento:\n",
    "learning_rate = 2e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tuned_transformer.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Número máximo de épocas\n",
    "max_epochs = 15\n",
    "total_steps = len(train_dataLoader) * max_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Entrenamiento con validación\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "tuned_transformer = tuned_transformer.to(device) \n",
    "best_val_accuracy = 0.0\n",
    "# Implementamos Early Stopping\n",
    "early_stopping_patience = 3\n",
    "epochs_without_improvement = 0\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    tuned_transformer.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for step, (texts, labels) in enumerate(train_dataLoader):\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Tokenizamos los textos con el modelo de SentenceTransformer\n",
    "        input_tokens = sent_transformer.tokenize(texts)\n",
    "        inputs_ids = input_tokens['input_ids'].to(device)\n",
    "        attention_mask = input_tokens['attention_mask'].to(device)\n",
    "        inputs_final = {\n",
    "            'input_ids': inputs_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "        logits = tuned_transformer(inputs_final)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        act_loss = loss.item()\n",
    "        running_loss += act_loss\n",
    "        \n",
    "        if step % 101 == 0:\n",
    "            print(f\"Epoch: {epoch+1}/{max_epochs}, Step: {step}/{len(train_dataLoader)}, Loss: {act_loss:4f}, Avg Loss: {running_loss/(step+1):.3f}\")\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataLoader)\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "    loss_list.append(epoch_loss)\n",
    "    \n",
    "    # Validación\n",
    "    tuned_transformer.eval()\n",
    "    val_pred = []\n",
    "    val_labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in val_dataLoader:\n",
    "            labels = labels.to(device)\n",
    "            inputs = sent_transformer.tokenize(texts)\n",
    "            inputs_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "            inputs_final = {\n",
    "                'input_ids': inputs_ids,\n",
    "                'attention_mask': attention_mask\n",
    "            }\n",
    "            logits = tuned_transformer(inputs_final)\n",
    "            \n",
    "            # Extraemos las predicciones\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            val_pred.extend(predictions.cpu().numpy())\n",
    "            val_labels_list.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculamos la precisión de validación\n",
    "    val_accuracy = accuracy_score(val_labels_list, val_pred)\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # early sttopping:\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"New best model found with accuracy: {best_val_accuracy:.4f}. Saving model...\")\n",
    "        sent_transformer.save(f\"best_models/sentiment/epoch_{epoch+1}\")\n",
    "        best_epoch = epoch + 1\n",
    "        print(\"Model saved.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"No improvement in validation accuracy for {epochs_without_improvement} epochs.\")\n",
    "        \n",
    "    if epochs_without_improvement >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(f\"Training completed. Best validation accuracy: {best_val_accuracy:.4f}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta salida de resultados la almacenamos un un fichero txt para poder parsearla y obtener los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_training_log(file_path):\n",
    "    # Patrones para extraer datos\n",
    "    train_pattern = re.compile(r\"Epoch (\\d+)/\\d+, Training Loss: (\\d+\\.\\d+)\")\n",
    "    val_pattern = re.compile(r\"Validation Accuracy: (\\d+\\.\\d{4})\")\n",
    "    \n",
    "    data = []\n",
    "    current_epoch = None\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Buscar línea de entrenamiento\n",
    "            train_match = train_pattern.search(line)\n",
    "            if train_match:\n",
    "                current_epoch = int(train_match.group(1))\n",
    "                train_loss = float(train_match.group(2))\n",
    "                data.append({\"Epoch\": current_epoch, \"Training Loss\": train_loss})\n",
    "            \n",
    "            # Buscar línea de validación (solo si ya encontramos una época)\n",
    "            val_match = val_pattern.search(line)\n",
    "            if val_match and current_epoch is not None:\n",
    "                val_accuracy = float(val_match.group(1))\n",
    "                # Actualizar la entrada correspondiente\n",
    "                for entry in data:\n",
    "                    if entry[\"Epoch\"] == current_epoch:\n",
    "                        entry[\"Validation Accuracy\"] = val_accuracy\n",
    "                        break\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_training_log(\"sentiment_results/results_training.txt\")\n",
    "\n",
    "# Guardar en CSV\n",
    "df.to_csv(\"training_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en training_results.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Datos guardados en training_results.csv\")\n",
    "\n",
    "df = pd.read_csv(\"sentiment_results/training_results.csv\")\n",
    "# Crear gráficas\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gráfica de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df[\"Epoch\"], df[\"Training Loss\"], \"b-o\")\n",
    "plt.title(\"Evolución de la Pérdida\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Gráfica de precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df[\"Epoch\"], df[\"Validation Accuracy\"], \"r-s\")\n",
    "plt.title(\"Evolución de la Precisión\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos en la gráfica cómo la estrategia early stopping ha funcionado correctamente, ya que la pérdida de validación no ha mejorado durante 3 épocas. Esto indica que el modelo ha alcanzado su mejor rendimiento en la época 5 y no se beneficiará de más entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia sobre el conjunto de test\n",
    "Usamos un árbol xgboost para hacer la inferencia sobre el conjunto de test, metiéndole como entradas las salidas del modelo de clasificación de texto sobre el que se ha hecho fine-tuning y el modelo original. El objetivo es contrastar la diferencia de resultados entre ambos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6445\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "df_train[\"OriginalTweet_emb\"] = df_train[\"OriginalTweet\"].apply(\n",
    "    lambda x: model.encode(x)\n",
    ")\n",
    "df_test[\"OriginalTweet_emb\"] = df_test[\"OriginalTweet\"].apply(\n",
    "    lambda x: model.encode(x)\n",
    ")\n",
    "\n",
    "X_train = pd.DataFrame(\n",
    "    df_train[\"OriginalTweet_emb\"].to_list(),\n",
    "    index=df_train.index,\n",
    "    dtype=float,\n",
    ")\n",
    "X_test = pd.DataFrame(\n",
    "    df_test[\"OriginalTweet_emb\"].to_list(),\n",
    "    index=df_test.index,\n",
    "    dtype=float,\n",
    ")\n",
    "y_train = df_train[\"label\"]\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(df_train['label'].unique()),\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "training_rounds = 100\n",
    "bst=xgb.train(param, dtrain, training_rounds)\n",
    "preds = bst.predict(dtest)\n",
    "accuracy_initial_model = accuracy_score(y_test, preds)\n",
    "print(f\"Accuracy: {accuracy_initial_model:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9150\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = SentenceTransformer(f\"best_models/sentiment/epoch_{best_epoch}\")\n",
    "\n",
    "df_train[\"OriginalTweet_tuned\"] = df_train[\"OriginalTweet\"].apply(\n",
    "    lambda x: model.encode(x)\n",
    ")\n",
    "df_test[\"OriginalTweet_tuned\"] = df_test[\"OriginalTweet\"].apply(\n",
    "    lambda x: model.encode(x)\n",
    ")\n",
    "\n",
    "X_train = pd.DataFrame(\n",
    "    df_train[\"OriginalTweet_tuned\"].to_list(),\n",
    "    index=df_train.index,\n",
    "    dtype=float,\n",
    ")\n",
    "X_test = pd.DataFrame(\n",
    "    df_test[\"OriginalTweet_tuned\"].to_list(),\n",
    "    index=df_test.index,\n",
    "    dtype=float,\n",
    ")\n",
    "y_train = df_train[\"label\"]\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(df_train['label'].unique()),\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "training_rounds = 100\n",
    "bst=xgb.train(param, dtrain, training_rounds)\n",
    "preds = bst.predict(dtest)\n",
    "accuracy_initial_model = accuracy_score(y_test, preds)\n",
    "print(f\"Accuracy: {accuracy_initial_model:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha demostrado la eficacia del modelo fine-tuned, ya que ha superado en un 27% al modelo original. Esto indica que el fine-tuning ha mejorado significativamente el rendimiento del modelo en la tarea de clasificación de sentimientos en tweets relacionados con el COVID-19."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
